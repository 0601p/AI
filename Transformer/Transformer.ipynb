{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4742,"status":"ok","timestamp":1675393156250,"user":{"displayName":"박민수","userId":"02095835357899527286"},"user_tz":-540},"id":"-qDTMmteNlB_","outputId":"a2764d7f-1f0b-4c1a-aeda-a2d355b4094b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchdata\n","  Downloading torchdata-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchdata) (1.13.1+cu116)\n","Collecting portalocker>=2.0.0\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Collecting urllib3>=1.25\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.25.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchdata) (4.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (4.0.0)\n","Installing collected packages: urllib3, portalocker, torchdata\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed portalocker-2.7.0 torchdata-0.5.1 urllib3-1.26.14\n"]}],"source":["!pip install torchdata"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4368,"status":"ok","timestamp":1675393160613,"user":{"displayName":"박민수","userId":"02095835357899527286"},"user_tz":-540},"id":"F_GerEypNlCC","outputId":"f4c82af4-5bec-46c3-80c4-ef8539aadd65"},"outputs":[{"name":"stdout","output_type":"stream","text":["using cuda\n"]}],"source":["import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","import numpy\n","import math\n","import torchdata\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","print(\"using\", device)\n","\n","torch.manual_seed(777)\n","if device == 'cuda':\n","    torch.cuda.manual_seed(777)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XLdhdsZKNlCC"},"outputs":[],"source":["norm_eps = 1e-5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahiaZtVtNlCD"},"outputs":[],"source":["class multiheadattention(torch.nn.Module):\n","    def __init__(self, h, d_embed, d_model, dr_rate = 0.1):\n","        super(multiheadattention, self).__init__()\n","        self.d_model = d_model\n","        self.h = h\n","        self.q_fc = torch.nn.Linear(d_embed, d_model).to(device)\n","        self.k_fc = torch.nn.Linear(d_embed, d_model).to(device)\n","        self.v_fc = torch.nn.Linear(d_embed, d_model).to(device)\n","        self.out_fc = torch.nn.Linear(d_model, d_embed).to(device)\n","        self.dropout = torch.nn.Dropout(p=dr_rate)\n","\n","    def forward(self, query, key, value, mask=None):\n","        n_batch = query.size(0)\n","        d_k = self.d_model // self.h\n","        \n","        query_t = self.q_fc(query).view(n_batch, -1, self.h, d_k).transpose(1, 2)\n","        key_t = self.k_fc(key).view(n_batch, -1, self.h, d_k).transpose(1, 2)\n","        value_t = self.v_fc(value).view(n_batch, -1, self.h, d_k).transpose(1, 2)\n","        \n","        score = torch.matmul(query_t, key_t.transpose(-1, -2)) / math.sqrt(d_k)\n","        if mask is not None:\n","            score = score.masked_fill(mask, -1e9)\n","        prob = torch.nn.functional.softmax(score, dim=-1)\n","        prob = self.dropout(prob)\n","        out = torch.matmul(prob, value_t)\n","\n","        out = out.transpose(1, 2)\n","        out = out.contiguous().view(n_batch, -1, self.d_model)\n","        out = self.out_fc(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mWgVm8hcNlCD"},"outputs":[],"source":["class PositionWiseFeedForardLayer(torch.nn.Module):\n","    def __init__(self, d_embed, d_ff, dr_rate = 0.1):\n","        super(PositionWiseFeedForardLayer, self).__init__()\n","        self.fc1 = torch.nn.Linear(d_embed, d_ff).to(device)\n","        self.fc2 = torch.nn.Linear(d_ff, d_embed).to(device)\n","        self.relu = torch.nn.ReLU()\n","        self.dropout = torch.nn.Dropout(p=dr_rate)\n","    \n","    def forward(self, x):\n","        return self.fc2(self.dropout(self.relu(self.fc1(x))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43E01DljNlCE"},"outputs":[],"source":["class encoder_block(torch.nn.Module):\n","    def __init__(self, h, d_model, d_embed, d_ff, dr_rate = 0.1):\n","        super(encoder_block, self).__init__()\n","        self.attention = multiheadattention(d_model = d_model, d_embed=d_embed, h=h)\n","        self.feed_forward = PositionWiseFeedForardLayer(d_embed=d_embed, d_ff=d_ff)\n","        self.norm1 = torch.nn.LayerNorm(d_embed, eps = norm_eps)\n","        self.norm2 = torch.nn.LayerNorm(d_embed, eps = norm_eps)\n","        self.dropout = torch.nn.Dropout(p=dr_rate)\n","    \n","    def forward(self, x, mask):\n","        residual = x\n","        out = self.norm1(residual)\n","        out = self.attention(out, out, out, mask)\n","        out = self.dropout(out)\n","        out = out + residual\n","        residual = out\n","        out = self.norm2(residual)\n","        out = self.feed_forward(out)\n","        out = self.dropout(out)\n","        out = out + residual\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kd0fzY5VNlCE"},"outputs":[],"source":["class encoder(torch.nn.Module):\n","    def __init__(self, h, d_model, d_embed, d_ff, n_layer):\n","        super(encoder, self).__init__()\n","        self.layers = torch.nn.ModuleList([encoder_block(h, d_model, d_embed, d_ff) for _ in range(n_layer)])\n","        self.norm = torch.nn.LayerNorm(d_embed, eps = norm_eps)\n","    def forward(self, x, mask):\n","        out = x\n","        for layer in self.layers:\n","            out = layer(out, mask)\n","        out = self.norm(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uND6NxxuNlCF"},"outputs":[],"source":["class decoder_block(torch.nn.Module):\n","    def __init__(self, h, d_model, d_embed, d_ff, dr_rate = 0.1):\n","        super(decoder_block, self).__init__()\n","        self.self_attention = multiheadattention(d_model = d_model, d_embed=d_embed, h=h)\n","        self.cross_attention = multiheadattention(d_model = d_model, d_embed=d_embed, h=h)\n","        self.feed_forward = PositionWiseFeedForardLayer(d_embed=d_embed, d_ff=d_ff)\n","        self.norm1 = torch.nn.LayerNorm(d_embed, eps = norm_eps)\n","        self.norm2 = torch.nn.LayerNorm(d_embed, eps = norm_eps)\n","        self.norm3 = torch.nn.LayerNorm(d_embed, eps = norm_eps)\n","        self.dropout = torch.nn.Dropout(p=dr_rate)\n","    \n","    def forward(self, z, o, tgt_mask, src_tgt_mask):\n","        residual = z\n","        out = self.norm1(residual)\n","        out = self.self_attention(out, out, out, tgt_mask)\n","        out = self.dropout(out)\n","        out = out + residual\n","        residual = out\n","        out = self.norm2(residual)\n","        out = self.cross_attention(out, o, o, src_tgt_mask)\n","        out = self.dropout(out)\n","        out = out + residual\n","        residual = out\n","        out = self.norm3(residual)\n","        out = self.feed_forward(out)\n","        out = self.dropout(out)\n","        out = out + residual\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mNws9wzhNlCF"},"outputs":[],"source":["class decoder(torch.nn.Module):\n","    def __init__(self, h, d_model, d_embed, d_ff, n_layer):\n","        super(decoder, self).__init__()\n","        self.norm = torch.nn.LayerNorm(d_embed, eps = norm_eps)\n","        self.layers = torch.nn.ModuleList([decoder_block(h, d_model, d_embed, d_ff) for _ in range(n_layer)])\n","    \n","    def forward(self, z, o, tgt_mask, src_tgt_mask):\n","        out = z\n","        for layer in self.layers:\n","            out = layer(out, o, tgt_mask, src_tgt_mask)\n","        out = self.norm(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwE7WrPENlCG"},"outputs":[],"source":["class TokenEmbedding(torch.nn.Module):\n","    def __init__(self, d_embed, vocab_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = torch.nn.Embedding(vocab_size, d_embed)\n","        self.d_embed = d_embed\n","    \n","    def forward(self, x):\n","        return self.embedding(x) * math.sqrt(self.d_embed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aDPTWhBLNlCG"},"outputs":[],"source":["class PositionalEncoding(torch.nn.Module):\n","    def __init__(self, d_embed, max_len = 256):\n","        super(PositionalEncoding, self).__init__()\n","        encoding = torch.zeros(max_len, d_embed)\n","        encoding.requires_grad = False\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_embed, 2) * -(math.log(10000.0) / d_embed))\n","        encoding[:, 0::2] = torch.sin(position * div_term)\n","        encoding[:, 1::2] = torch.cos(position * div_term)\n","        self.encoding = encoding.unsqueeze(0).to(device)\n","    \n","    def forward(self, x):\n","        seq_len = x.size(1)\n","        pos_embed = self.encoding[:, :seq_len, :]\n","        out = x + pos_embed\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bIN1dBL9NlCG"},"outputs":[],"source":["class TransformerEmbedding(torch.nn.Module):\n","    def __init__(self, d_embed, vocab_size, max_len):\n","        super(TransformerEmbedding, self).__init__()\n","        self.embed = TokenEmbedding(d_embed=d_embed, vocab_size=vocab_size)\n","        self.positional = PositionalEncoding(d_embed=d_embed, max_len=max_len)\n","    \n","    def forward(self, x):\n","        return self.positional(self.embed(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzRKBmroNlCG"},"outputs":[],"source":["class Transformer(torch.nn.Module):\n","    def __init__(self, src_vocab_size, tgt_vocab_size, max_len, d_embed, n_layer, d_model, h, d_ff):\n","        super(Transformer, self).__init__()\n","        self.src_embed = TransformerEmbedding(d_embed=d_embed, vocab_size=src_vocab_size, max_len=max_len)\n","        self.tgt_embed = TransformerEmbedding(d_embed=d_embed, vocab_size=tgt_vocab_size, max_len=max_len)\n","        self.generator = torch.nn.Linear(d_model, tgt_vocab_size).to(device)\n","        self.encoder = encoder(h, d_model, d_embed, d_ff, n_layer)\n","        self.decoder = decoder(h, d_model, d_embed, d_ff, n_layer)\n","    \n","    def forward(self, x, z):\n","        src_mask = self.make_src_mask(x)\n","        tgt_mask = self.make_tgt_mask(z)\n","        src_tgt_mask = self.make_src_tgt_mask(x, z)\n","        c = self.encoder(self.src_embed(x), src_mask)\n","        y = self.decoder(self.tgt_embed(z), c, tgt_mask, src_tgt_mask)\n","        y = torch.nn.functional.log_softmax(self.generator(y), dim=2)\n","        return y\n","    \n","    def make_pad_mask(self, query, key, pad_idx = 3):\n","        query_seq_len, key_seq_len = query.size(1), key.size(1)\n","        key_mask = key.ne(pad_idx).unsqueeze(1).unsqueeze(2).repeat(1, 1, query_seq_len, 1)\n","        query_mask = query.ne(pad_idx).unsqueeze(1).unsqueeze(3).repeat(1, 1, 1, key_seq_len)\n","        mask = key_mask & query_mask\n","        mask.requires_grad = False\n","        return mask\n","    \n","    def make_subsequent_mask(self, query, key):\n","        query_seq_len, key_seq_len = query.size(1), key.size(1)\n","        tril = numpy.tril(numpy.ones((query_seq_len, key_seq_len)), k=0).astype('uint8') # lower triangle without diagonal\n","        mask = torch.tensor(tril, dtype=torch.bool, requires_grad=False, device=device)\n","        return mask\n","    \n","    def make_src_mask(self, src):\n","        return self.make_pad_mask(src, src)\n","    \n","    def make_tgt_mask(self, tgt):\n","        pad_mask = self.make_pad_mask(tgt, tgt)\n","        seq_mask = self.make_subsequent_mask(tgt, tgt)\n","        return pad_mask & seq_mask\n","    \n","    def make_src_tgt_mask(self, src, tgt):\n","        return self.make_pad_mask(tgt, src)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":268},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1675393160615,"user":{"displayName":"박민수","userId":"02095835357899527286"},"user_tz":-540},"id":"q7OISjlPNlCH","outputId":"b19a845c-7cfc-4cf9-a402-2952dbf5f552"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ndef build_model(src_vocab_size, tgt_vocab_size, device=\"cuda\", max_len=256, d_embed=512, n_layer=6, d_model=512, h=8, d_ff=2048):\\n    \\n    #attention = multiheadattention(d_model = d_model, h=h, q_fc=torch.nn.Linear(d_embed, d_model).to(device), k_fc=torch.nn.Linear(d_embed, d_model).to(device), v_fc=torch.nn.Linear(d_embed, d_model).to(device), out_fc=torch.nn.Linear(d_model, d_embed).to(device))\\n    #position_ff = PositionWiseFeedForardLayer(fc1=torch.nn.Linear(d_embed, d_ff).to(device), fc2=torch.nn.Linear(d_ff, d_embed).to(device))\\n    #encoder_blk = encoder_block(attention=copy.deepcopy(attention), feed_forward=copy.deepcopy(position_ff))\\n    #decoder_blk = decoder_block(self_attention=copy.deepcopy(attention), cross_attention=copy.deepcopy(attention), feed_forward=copy.deepcopy(position_ff))\\n    #ecd = encoder(encoder_block=encoder_blk, n_layer=n_layer)\\n    #dcd = decoder(decoder_block=decoder_blk, n_layer=n_layer)\\n    \\n    model = Transformer(src_vocab_size=src_vocab_size, tgt_vocab_size=tgt_vocab_size, max_len=256, d_embed=512, n_layer=6, d_model=512, h=8, d_ff=2048, generator=generator).to(device)\\n    model.device = device\\n\\n    return model\\n'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","def build_model(src_vocab_size, tgt_vocab_size, device=\"cuda\", max_len=256, d_embed=512, n_layer=6, d_model=512, h=8, d_ff=2048):\n","    \n","    #attention = multiheadattention(d_model = d_model, h=h, q_fc=torch.nn.Linear(d_embed, d_model).to(device), k_fc=torch.nn.Linear(d_embed, d_model).to(device), v_fc=torch.nn.Linear(d_embed, d_model).to(device), out_fc=torch.nn.Linear(d_model, d_embed).to(device))\n","    #position_ff = PositionWiseFeedForardLayer(fc1=torch.nn.Linear(d_embed, d_ff).to(device), fc2=torch.nn.Linear(d_ff, d_embed).to(device))\n","    #encoder_blk = encoder_block(attention=copy.deepcopy(attention), feed_forward=copy.deepcopy(position_ff))\n","    #decoder_blk = decoder_block(self_attention=copy.deepcopy(attention), cross_attention=copy.deepcopy(attention), feed_forward=copy.deepcopy(position_ff))\n","    #ecd = encoder(encoder_block=encoder_blk, n_layer=n_layer)\n","    #dcd = decoder(decoder_block=decoder_blk, n_layer=n_layer)\n","    \n","    model = Transformer(src_vocab_size=src_vocab_size, tgt_vocab_size=tgt_vocab_size, max_len=256, d_embed=512, n_layer=6, d_model=512, h=8, d_ff=2048, generator=generator).to(device)\n","    model.device = device\n","\n","    return model\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2938,"status":"ok","timestamp":1675393163543,"user":{"displayName":"박민수","userId":"02095835357899527286"},"user_tz":-540},"id":"lsHdDUllNlCH","outputId":"abe0b2dd-b400-4a9d-c16d-bdb39d223753"},"outputs":[{"name":"stdout","output_type":"stream","text":["index 0\n","Two young, White males are outside near many bushes.\n","Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n","index 1\n","Several men in hard hats are operating a giant pulley system.\n","Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\n","index 2\n","A little girl climbing into a wooden playhouse.\n","Ein kleines Mädchen klettert in ein Spielhaus aus Holz.\n","index 3\n","A man in a blue shirt is standing on a ladder cleaning a window.\n","Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.\n","index 4\n","Two men are at the stove preparing food.\n","Zwei Männer stehen am Herd und bereiten Essen zu.\n"]}],"source":["import torchdata\n","import random\n","from torchtext.datasets import Multi30k\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.nn.utils.rnn import pad_sequence\n","\n","multi_train, multi_valid, multi_test = Multi30k(language_pair=('en', 'de'))\n","for i, (eng, de) in enumerate(multi_train):\n","    if i==5:\n","        break\n","    print(\"index\", i)\n","    print(eng)\n","    print(de)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26325,"status":"ok","timestamp":1675393189860,"user":{"displayName":"박민수","userId":"02095835357899527286"},"user_tz":-540},"id":"d-MY3Q8pNlCH","outputId":"cfa7af6b-a537-49f9-c11c-7a75e829dc73"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-02-03 02:59:26.008350: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-sm==3.4.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.4.1) (3.4.4)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.7)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.4)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (6.3.0)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.12)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (57.4.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (23.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.25.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.4.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.12.7)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","2023-02-03 02:59:39.860514: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting de-core-news-sm==3.4.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from de-core-news-sm==3.4.0) (3.4.4)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (6.3.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.21.6)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.8)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.10.4)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (23.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.25.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.12)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (57.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.9)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.4)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.7)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.11.3)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.26.14)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n","Installing collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-3.4.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('de_core_news_sm')\n"]}],"source":["!python -m spacy download en_core_web_sm\n","!python -m spacy download de_core_news_sm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14670,"status":"ok","timestamp":1675393204525,"user":{"displayName":"박민수","userId":"02095835357899527286"},"user_tz":-540},"id":"ZLx_l7s3NlCH","outputId":"b39cd42a-18f7-488b-e62e-dff204262176"},"outputs":[{"name":"stdout","output_type":"stream","text":["English vocab size : 6191\n","Deutsch vocab size : 8014\n"]}],"source":["en_tokenizer = get_tokenizer(tokenizer='spacy', language='en_core_web_sm')\n","de_tokenizer = get_tokenizer(tokenizer='spacy', language='de_core_news_sm')\n","en_vocab = build_vocab_from_iterator(map(en_tokenizer, [english for english, _ in multi_train]), min_freq=2, specials=[\"<unk>\", \"<sos>\", \"<eos>\", \"<pad>\"])\n","de_vocab = build_vocab_from_iterator(map(de_tokenizer, [de for _ , de in multi_train]), min_freq=2, specials=[\"<unk>\", \"<sos>\", \"<eos>\", \"<pad>\"])\n","en_token2id = en_vocab.get_stoi()\n","de_token2id = de_vocab.get_stoi()\n","\n","en_id2token = en_vocab.get_itos()\n","de_id2token = de_vocab.get_itos()\n","\n","en_vocab_size = len(en_token2id)\n","de_vocab_size = len(de_token2id)\n","\n","print(\"English vocab size :\", len(en_token2id))\n","print(\"Deutsch vocab size :\", len(de_token2id))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qCNbNKX0NlCH"},"outputs":[],"source":["class language:\n","    unk_token_id = 0\n","    sos_token_id = 1\n","    eos_token_id = 2\n","    pad_token_id = 3\n","\n","    def __init__(self, src_tokenizer, tgt_tokenizer, src_token2id, tgt_token2id, src_id2token, tgt_id2token):\n","        self.src_tokenizer = src_tokenizer\n","        self.tgt_tokenizer = tgt_tokenizer\n","\n","        self.src_token2id = src_token2id\n","        self.tgt_token2id = tgt_token2id\n","\n","        self.src_id2token = src_id2token\n","        self.tgt_id2token = tgt_id2token\n","    \n","    def src_encode(self, src_text):\n","        source_token = [self.src_token2id.get(token, self.unk_token_id) for token in self.src_tokenizer(src_text)]\n","        return source_token\n","\n","    def tgt_encode(self, tgt_text):\n","        target_token = [self.sos_token_id] + [self.tgt_token2id.get(token, self.unk_token_id) for token in self.tgt_tokenizer(tgt_text)] + [self.eos_token_id]\n","        return target_token\n","\n","    def src_decode(self, src_token):\n","        source_sentence = list(map(lambda x: self.src_id2token[x], src_token))\n","        return \" \".join(source_sentence)\n","\n","    def tgt_decode(self, tgt_token):\n","        source_sentence = list(map(lambda x: self.tgt_id2token[x], tgt_token))[1:-1]\n","        return \" \".join(source_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"76nL8GafNlCH"},"outputs":[],"source":["class MultiDataset(torch.utils.data.Dataset):\n","    def __init__(self, data, language):\n","        self.data = data\n","        self.language = language\n","        self.sentences = self.preprocess()\n","\n","    def preprocess(self):\n","        sentences = [(self.language.src_encode(eng), self.language.tgt_encode(de)) for eng, de in self.data if len(eng) > 0 and len(de) > 0]\n","        return sentences\n","\n","    def __getitem__(self, idx):\n","        return self.sentences[idx]\n","    \n","    def __len__(self):\n","        return len(self.sentences)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rkIPYQT9NlCI"},"outputs":[],"source":["language_preprocess = language(en_tokenizer, de_tokenizer, en_token2id, de_token2id, en_id2token, de_id2token)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GN6GAk5GNlCI"},"outputs":[],"source":["multi_train_dataset = MultiDataset(multi_train, language_preprocess)\n","multi_val_dataset = MultiDataset(multi_valid, language_preprocess)\n","#multi_test_dataset = MultiDataset(multi_test, language_preprocess)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1675393207734,"user":{"displayName":"박민수","userId":"02095835357899527286"},"user_tz":-540},"id":"GJSbKAteNlCI","outputId":"5e36b898-2fce-4bdf-c562-f7b5b640fd79"},"outputs":[{"name":"stdout","output_type":"stream","text":["29000\n","1014\n"]}],"source":["print(len(multi_train_dataset))\n","print(len(multi_val_dataset))\n","#print(len(multi_test_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KNojM15DNlCI"},"outputs":[],"source":["def collate_fn(batch_samples):\n","    src_sentences = pad_sequence([torch.tensor(src) for src, _ in batch_samples], batch_first=True, padding_value=language_preprocess.pad_token_id)\n","    tgt_sentences = pad_sequence([torch.tensor(tgt) for _, tgt in batch_samples], batch_first=True, padding_value=language_preprocess.pad_token_id)\n","    return src_sentences, tgt_sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u8cSAAiTNlCI"},"outputs":[],"source":["def batch_sampling(sequence_lengths, batch_size):\n","    seq_lens = [(i, seq_len, tgt_len) for i, (seq_len, tgt_len) in enumerate(sequence_lengths)]\n","    seq_lens = sorted(seq_lens, key = lambda x:x[1])\n","    seq_lens = [sample[0] for sample in seq_lens]\n","    sample_indices = [seq_lens[i:i+batch_size] for i in range(0, len(seq_lens), batch_size)]\n","    random.shuffle(sample_indices)\n","    return sample_indices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2_bQjBtWNlCI"},"outputs":[],"source":["batch_size = 100\n","seq_lengths = list(map(lambda x: (len(x[0]), len(x[1])), multi_train_dataset))\n","batch_sampler = batch_sampling(seq_lengths, batch_size)\n","train_loader = torch.utils.data.DataLoader(multi_train_dataset, collate_fn=collate_fn, batch_sampler=batch_sampler)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKeru_lWNlCI"},"outputs":[],"source":["def train_epoch(model, data_loader, optimizer, criterion):\n","    model.train()\n","    loss_epoch = 0\n","    for idx, (src, tgt) in enumerate(data_loader):\n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","        tgt_x = tgt[:, :-1]\n","        tgt_y = tgt[:, 1:]\n","\n","        optimizer.zero_grad()\n","        \n","        output = model(src, tgt_x)\n","        y_hat = output.contiguous().view(-1, output.shape[-1])\n","        y_gt = tgt_y.contiguous().view(-1)\n","        loss = criterion(y_hat, y_gt)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","        loss_epoch += loss.item()\n","    \n","    return loss_epoch / (idx + 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t2Wf-00TNlCI"},"outputs":[],"source":["def eval(model, data_loader, criterion, print_first_batch):\n","    model.eval()\n","    loss_epoch = 0\n","    with torch.no_grad():\n","        for idx, (src, tgt) in enumerate(data_loader):\n","            src = src.to(device)\n","            tgt = tgt.to(device)\n","            tgt_x = tgt[:, :-1]\n","            tgt_y = tgt[:, 1:]\n","            \n","            output = model(src, tgt_x)\n","            y_hat = output.contiguous().view(-1, output.shape[-1])\n","            y_gt = tgt_y.contiguous().view(-1)\n","            loss = criterion(y_hat, y_gt)\n","\n","            if print_first_batch:\n","                for i in range(10):\n","                    source = language_preprocess.src_decode(src[i, :])\n","                    target = language_preprocess.tgt_decode(tgt[i, :])\n","                    predict = language_preprocess.tgt_decode(torch.argmax(output[i, :], dim=1))\n","                    print(i, \"en :\" ,source)\n","                    print(i, \"gt :\" ,target)\n","                    print(i, \"de :\", predict)\n","                print_first_batch = False\n","            \n","            loss_epoch += loss.item()\n","    \n","    return loss_epoch / (idx + 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0gD-ZvbNlCI"},"outputs":[],"source":["def train(model, data_loader, optimizer, scheduler, criterion, epoch):\n","    for i in range(epoch):\n","        train_loss = train_epoch(model, data_loader, optimizer, criterion)\n","        print(\"EPOCH[\" + str(i) + \"] Train Loss : \" + str(train_loss))\n","        scheduler.step()\n","        if(i % 10 == 0):\n","            print(\"Eval\")\n","            eval_loss = eval(model, data_loader, criterion, True)\n","            print(\"Eval Loss : \" + str(eval_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2448356,"status":"ok","timestamp":1675395781340,"user":{"displayName":"박민수","userId":"02095835357899527286"},"user_tz":-540},"id":"nk5gh0wxNlCJ","outputId":"90779e23-fc8c-48ec-baa0-241a2cbffae0"},"outputs":[{"name":"stdout","output_type":"stream","text":["EPOCH[0] Train Loss : 2.3937683561752583\n","Eval\n","0 en : A woman in a blue top and hat is stretching or performing yoga on the beach .\n","0 de : Frau mit Hut in einem Jungen Frauen macht am Strand trinkt in umher . <eos> <eos> <eos> <eos> <eos>\n","1 en : A young man in odd clothes leaning against a brick wall with a garden in it .\n","1 de : junger Mann in <unk> Kleidung , an einer Bank , die einen Baumstamm verkauft . <eos> <eos> <eos> <eos>\n","2 en : Two men are looking toward the ground while one is wearing gloves and holding a tool .\n","2 de : Männer bereiten zum Kleidung , die weißen ihnen trägt Jacke und hält ein Bild . <eos> <eos> <eos> <eos>\n","3 en : A young child with a gray shirt and pacifier is standing next to a toy horse .\n","3 de : kleines Kind mit einem grauen Hemd und <unk> steht neben einem Pool . <eos> <eos> <eos> <eos> <eos> <eos>\n","4 en : Three blond girls and a dark - haired girl try to sell decorated <unk> and rocks .\n","4 de : arbeiten Mädchen und ein großes Mädchen schläft , <unk> Armen und bereiten zu Fuß . <eos> <eos> <eos> <eos>\n","5 en : A group of people sit on the beach , beyond a sign warning of <unk> waves .\n","5 de : Gruppe von Menschen sitzt am Strand einem einem , , das vor <unk> der <unk> . <eos> <eos> <eos>\n","6 en : A man in sunglasses is writing on a pad with his bike leaned up against him .\n","6 de : Mann mit einem schläft einem einem Spielplatz , neben ihm steht an der auf sein Fahrrad . <eos> <eos>\n","7 en : A guy with a pink shirt sitting on the ground , drawing a peacock with chalk .\n","7 de : Mann mit Brille Hemd sitzt auf dem Boden und blickt mit einer einen Kürbis . <eos> <eos> <eos> <eos>\n","8 en : A man and a woman in bathing suits hold each other in a body of water .\n","8 de : Mann und eine Frau in legerer großen telefoniert in einem öffentlichen . <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n","9 en : A woman holds a \" car wash \" sign on the edge of a quiet street .\n","9 de : Frau hält ein grünes <unk> <unk> am Rand einer Baustelle Straße . <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n","Eval Loss : 1.5732396762946557\n","EPOCH[1] Train Loss : 2.6095515534795566\n","EPOCH[2] Train Loss : 2.9501840065265523\n","EPOCH[3] Train Loss : 3.3131853695573477\n","EPOCH[4] Train Loss : 3.1437380387865264\n","EPOCH[5] Train Loss : 2.7054932339438076\n","EPOCH[6] Train Loss : 2.529166248337976\n","EPOCH[7] Train Loss : 2.5285195535626905\n","EPOCH[8] Train Loss : 2.481420624256134\n","EPOCH[9] Train Loss : 2.6821561048770772\n","EPOCH[10] Train Loss : 2.3979945252681603\n","Eval\n","0 en : A woman in a blue top and hat is stretching or performing yoga on the beach .\n","0 de : Frau mit Hut in einem schwarzen mit macht am Strand singt oder ist . <eos> <eos> Eine Eine Eine\n","1 en : A young man in odd clothes leaning against a brick wall with a garden in it .\n","1 de : junger Mann in einer junge an an einem grünen , die einen Garten vor . <eos> <eos> Eine Eine\n","2 en : Two men are looking toward the ground while one is wearing gloves and holding a tool .\n","2 de : Männer schauen sitzt , an einer von ihnen und Feld und hält ein Mikrofon . <eos> <eos> Zwei Zwei\n","3 en : A young child with a gray shirt and pacifier is standing next to a toy horse .\n","3 de : kleines mit mit einem blauen blauen und <unk> steht neben einem Skateboard . <eos> <eos> Eine Eine Eine Eine\n","4 en : Three blond girls and a dark - haired girl try to sell decorated <unk> and rocks .\n","4 de : Personen Gruppe in ein Foto <unk> <unk> <unk> <unk> , und Helmen zu verkaufen . <eos> <eos> Drei Drei\n","5 en : A group of people sit on the beach , beyond a sign warning of <unk> waves .\n","5 de : Gruppe von <unk> mit mit Strand sprechen , <unk> , das vor <unk> <unk> <unk> . <eos> <eos> Eine\n","6 en : A man in sunglasses is writing on a pad with his bike leaned up against him .\n","6 de : Mann sitzt einem fährt in einem grünen , neben steht im Baby Raum Mädchen sein Fahrrad . <eos> <eos>\n","7 en : A guy with a pink shirt sitting on the ground , drawing a peacock with chalk .\n","7 de : Mann mit roten mit mit auf dem Boden und ein mit Kreide einen Trick . <eos> <eos> Eine Eine\n","8 en : A man and a woman in bathing suits hold each other in a body of water .\n","8 de : Mann und eine Frau in einem Trikots mit in einem Gewässer . <eos> <eos> Eine Eine Eine Eine Eine\n","9 en : A woman holds a \" car wash \" sign on the edge of a quiet street .\n","9 de : Frau in ein <unk> <unk> <unk> am Rand einer Straße Straße . <eos> <eos> Eine Eine Eine Eine Eine\n","Eval Loss : 1.7400828542380498\n","EPOCH[11] Train Loss : 2.5593828678131105\n","EPOCH[12] Train Loss : 2.057341430927145\n","EPOCH[13] Train Loss : 2.1550538046606658\n","EPOCH[14] Train Loss : 1.970189779174739\n","EPOCH[15] Train Loss : 1.8353371879150127\n","EPOCH[16] Train Loss : 1.8002159724975455\n","EPOCH[17] Train Loss : 1.8485804909262165\n","EPOCH[18] Train Loss : 1.8529759980481246\n","EPOCH[19] Train Loss : 1.7085790112100798\n","EPOCH[20] Train Loss : 1.5062788194623487\n","Eval\n","0 en : A woman in a blue top and hat is stretching or performing yoga on the beach .\n","0 de : Frau mit Hut in einem schlammigen Oberteil am am Strand Ball oder winkt . <eos> <eos> Eine Eine Eine\n","1 en : A young man in odd clothes leaning against a brick wall with a garden in it .\n","1 de : junger Mann in einem Kleidung lehnt an einer blauen , die einen Garten vor . <eos> <eos> Ein Ein\n","2 en : Two men are looking toward the ground while one is wearing gloves and holding a tool .\n","2 de : Männer und und , , einer von ihnen trägt und und hält ein großes . <eos> <eos> Ein Ein\n","3 en : A young child with a gray shirt and pacifier is standing next to a toy horse .\n","3 de : kleines Kind mit einem grauen weißen und <unk> steht neben einem Spielzeugpferd . <eos> <eos> Ein Ein Ein Ein\n","4 en : Three blond girls and a dark - haired girl try to sell decorated <unk> and rocks .\n","4 de : Mädchen Mädchen und ein Mädchen Mädchen versuchen , <unk> und und Steine zu verkaufen . <eos> <eos> Gruppe Gruppe\n","5 en : A group of people sit on the beach , beyond a sign warning of <unk> waves .\n","5 de : Gruppe von Menschen fahren am Strand hinter einem Schild , das vor <unk> Wellen <unk> . <eos> <eos> Ein\n","6 en : A man in sunglasses is writing on a pad with his bike leaned up against him .\n","6 de : Mann fährt einem Herr arbeitet einem Tisch , neben ihm steht an hinter hinter sein Fahrrad . <eos> <eos>\n","7 en : A guy with a pink shirt sitting on the ground , drawing a peacock with chalk .\n","7 de : Mann mit roter und und Jacke dem Boden und malt mit Kreide einen Wald . <eos> <eos> Ein Ein\n","8 en : A man and a woman in bathing suits hold each other in a body of water .\n","8 de : Mann und eine Frau in Schwarz Uniform über in einem Gewässer . <eos> <eos> Ein Ein Ein Ein Ein\n","9 en : A woman holds a \" car wash \" sign on the edge of a quiet street .\n","9 de : Frau hält ein <unk> <unk> <unk> am Rand einer Band Straße . <eos> <eos> Frau Frau Frau Frau Frau\n","Eval Loss : 0.8939048901714127\n","EPOCH[21] Train Loss : 1.3969884732673907\n","EPOCH[22] Train Loss : 1.438755369597468\n","EPOCH[23] Train Loss : 1.316874656800566\n","EPOCH[24] Train Loss : 1.3082564529673806\n","EPOCH[25] Train Loss : 1.3620731389728087\n","EPOCH[26] Train Loss : 1.3479085194653477\n","EPOCH[27] Train Loss : 1.3159916575612693\n","EPOCH[28] Train Loss : 1.2935613923031708\n","EPOCH[29] Train Loss : 1.359298851572234\n","EPOCH[30] Train Loss : 1.2587953763789144\n","Eval\n","0 en : A woman in a blue top and hat is stretching or performing yoga on the beach .\n","0 de : Frau mit einem in einem Kanu Oberteil macht am Strand Stirnband oder geht . <eos> <eos> Eine Eine Eine\n","1 en : A young man in odd clothes leaning against a brick wall with a garden in it .\n","1 de : Mann Mann in <unk> lehnt steht an einer Ziegelmauer , die einen Garten umgibt . <eos> <eos> Ein Ein\n","2 en : Two men are looking toward the ground while one is wearing gloves and holding a tool .\n","2 de : Männer in , , , einer von ihnen trägt Parkplatz und hält ein Werkzeug . <eos> <eos> <unk> <unk>\n","3 en : A young child with a gray shirt and pacifier is standing next to a toy horse .\n","3 de : Kind Kind mit einem grauen Hemd und <unk> steht neben einem Spielzeugpferd . <eos> <eos> Ein Ein Ein Ein\n","4 en : Three blond girls and a dark - haired girl try to sell decorated <unk> and rocks .\n","4 de : Kinder und und ein Mädchen Mädchen , <unk> <unk> Feld und Steine zu verkaufen . <eos> <eos> rasen rasen\n","5 en : A group of people sit on the beach , beyond a sign warning of <unk> waves .\n","5 de : Gruppe von Menschen sitzt am Strand hinter einem Schild , das <unk> <unk> es <unk> . <eos> <eos> Eine\n","6 en : A man in sunglasses is writing on a pad with his bike leaned up against him .\n","6 de : Mann mit einem auf auf einem Seil , neben ihm steht an ihn Straße sein Fahrrad . <eos> <eos>\n","7 en : A guy with a pink shirt sitting on the ground , drawing a peacock with chalk .\n","7 de : Mann mit dem Hemd sitzt auf dem Boden und malt mit Kreide einen Baseball . <eos> <eos> Ein Ein\n","8 en : A man and a woman in bathing suits hold each other in a body of water .\n","8 de : Mann und eine Frau in Badekleidung halten reparieren in einem Gewässer . <eos> <eos> Frau Frau Frau Frau Frau\n","9 en : A woman holds a \" car wash \" sign on the edge of a quiet street .\n","9 de : Frau in <unk> <unk> <unk> <unk> am Rand einer Straße Straße . <eos> <eos> Eine Eine Eine Eine Eine\n","Eval Loss : 0.6633130029357713\n","EPOCH[31] Train Loss : 1.0789381900738026\n","EPOCH[32] Train Loss : 1.0860283580319634\n","EPOCH[33] Train Loss : 1.087334977141742\n","EPOCH[34] Train Loss : 1.0603610738598068\n","EPOCH[35] Train Loss : 1.0506224590128865\n","EPOCH[36] Train Loss : 0.9900247140177365\n","EPOCH[37] Train Loss : 1.0064390754905241\n","EPOCH[38] Train Loss : 0.9948148855875278\n","EPOCH[39] Train Loss : 1.082970457755286\n","EPOCH[40] Train Loss : 1.0670854733935717\n","Eval\n","0 en : A woman in a blue top and hat is stretching or performing yoga on the beach .\n","0 de : Frau in einem in einem Dreirad Oberteil macht am Strand Yoga oder Turm . <eos> <eos> Ein Ein Ein\n","1 en : A young man in odd clothes leaning against a brick wall with a garden in it .\n","1 de : Mann Mann in einem wandert lehnt an einer grauen , die einen Garten umgibt . <eos> <eos> <unk> <unk>\n","2 en : Two men are looking toward the ground while one is wearing gloves and holding a tool .\n","2 de : Männer schauen um , , von von ihnen trägt Handschuhe und hält ein Tuch . <eos> <eos> , ,\n","3 en : A young child with a gray shirt and pacifier is standing next to a toy horse .\n","3 de : kleines Kind mit kurzen blauen Hemd und <unk> steht neben einem Kleinkind . <eos> <eos> Ein Ein Ein Ein\n","4 en : Three blond girls and a dark - haired girl try to sell decorated <unk> and rocks .\n","4 de : und Mädchen und ein dunkelhaariges Mädchen , , <unk> Muscheln und Steine zu verkaufen . <eos> <eos> , ,\n","5 en : A group of people sit on the beach , beyond a sign warning of <unk> waves .\n","5 de : Gruppe von Menschen am am Strand hinter sein Schild , das vor <unk> Wellen <unk> . <eos> <eos> Ein\n","6 en : A man in sunglasses is writing on a pad with his bike leaned up against him .\n","6 de : Mann mit einem auf auf einem roten , neben ihm steht an ihn spricht sein Fahrrad . <eos> <eos>\n","7 en : A guy with a pink shirt sitting on the ground , drawing a peacock with chalk .\n","7 de : Mann mit einem Hemd sitzt auf dem Boden und malt mit Kreide einen Pfau . <eos> <eos> Ein Ein\n","8 en : A man and a woman in bathing suits hold each other in a body of water .\n","8 de : Mann und eine Frau in Badekleidung halten einander in einem Gewässer . <eos> <eos> Ein Ein Ein Ein Ein\n","9 en : A woman holds a \" car wash \" sign on the edge of a quiet street .\n","9 de : Frau ein ein <unk> <unk> <unk> am Rand einer ruhigen Straße . <eos> <eos> Ein Ein Ein Ein Ein\n","Eval Loss : 0.560754162098827\n","EPOCH[41] Train Loss : 0.8797716020510115\n","EPOCH[42] Train Loss : 0.8622885290404846\n","EPOCH[43] Train Loss : 1.96790271380852\n","EPOCH[44] Train Loss : 1.0553255308291007\n","EPOCH[45] Train Loss : 1.1624230980873107\n","EPOCH[46] Train Loss : 0.9857905742423287\n","EPOCH[47] Train Loss : 1.0313475038470894\n","EPOCH[48] Train Loss : 0.9632888225645855\n","EPOCH[49] Train Loss : 0.9129127475722083\n","EPOCH[50] Train Loss : 0.8481148007614859\n","Eval\n","0 en : A woman in a blue top and hat is stretching or performing yoga on the beach .\n","0 de : Frau in einem in einem blauem Oberteil macht am Strand fährt oder Decke . <eos> <eos> <unk> <unk> <unk>\n","1 en : A young man in odd clothes leaning against a brick wall with a garden in it .\n","1 de : junger Mann in <unk> lehnt lehnt an einer Ziegelmauer , die einen Garten Holz . <eos> <eos> <unk> <unk>\n","2 en : Two men are looking toward the ground while one is wearing gloves and holding a tool .\n","2 de : Männer , in , , einer Gruppe 8 trägt treten und hält ein Spielzeug . <eos> <eos> <unk> <unk>\n","3 en : A young child with a gray shirt and pacifier is standing next to a toy horse .\n","3 de : kleines Kind mit einem blauen Hemd und <unk> steht neben einem Stuhl . <eos> <eos> und und und und\n","4 en : Three blond girls and a dark - haired girl try to sell decorated <unk> and rocks .\n","4 de : Frauen Mädchen und ein dunkelhaariges Mädchen versuchen <unk> die Muscheln und Steine zu verkaufen . <eos> <eos> und und\n","5 en : A group of people sit on the beach , beyond a sign warning of <unk> waves .\n","5 de : Gruppe von Menschen sitzt am Strand Schild Schild Schild , das vor <unk> Wellen <unk> . <eos> <eos> <unk>\n","6 en : A man in sunglasses is writing on a pad with his bike leaned up against him .\n","6 de : Mann in einem einem auf einem roten neben die ihm steht an ihn hinter sein Fahrrad . <eos> <eos>\n","7 en : A guy with a pink shirt sitting on the ground , drawing a peacock with chalk .\n","7 de : Mann mit einem sitzt sitzt mit dem Boden malt malt mit Kreide einen Pfau . <eos> <eos> und und\n","8 en : A man and a woman in bathing suits hold each other in a body of water .\n","8 de : Mann und eine Frau in Badekleidung halten einander in einem Gewässer . <eos> <eos> und und und und und\n","9 en : A woman holds a \" car wash \" sign on the edge of a quiet street .\n","9 de : Frau hält ein <unk> <unk> <unk> am Rand einer ruhigen Straße . <eos> <eos> Frau Frau Frau Frau Frau\n","Eval Loss : 0.5944986600043445\n","EPOCH[51] Train Loss : 0.976644374173263\n","EPOCH[52] Train Loss : 0.8258208039505729\n","EPOCH[53] Train Loss : 0.913175886458364\n","EPOCH[54] Train Loss : 0.954870880472249\n","EPOCH[55] Train Loss : 1.0888917263211875\n","EPOCH[56] Train Loss : 1.0789260669001217\n","EPOCH[57] Train Loss : 1.0778851528619897\n","EPOCH[58] Train Loss : 1.0617207473721997\n","EPOCH[59] Train Loss : 0.9606283921619941\n","EPOCH[60] Train Loss : 0.9117902791191792\n","Eval\n","0 en : A woman in a blue top and hat is stretching or performing yoga on the beach .\n","0 de : Frau in Hut in einem blauem Oberteil macht am Strand Person oder fahren . <eos> <eos> <eos> <eos> <eos>\n","1 en : A young man in odd clothes leaning against a brick wall with a garden in it .\n","1 de : junger Mann in <unk> Kleidung an an einer Ziegelmauer , die einen Garten umgibt . <eos> <eos> <eos> <eos>\n","2 en : Two men are looking toward the ground while one is wearing gloves and holding a tool .\n","2 de : Männer schauen und an einer einer von ihnen trägt Handschuhe und hält ein Foto . <eos> <eos> <eos> <eos>\n","3 en : A young child with a gray shirt and pacifier is standing next to a toy horse .\n","3 de : kleines Kind mit einem grauen Hemd und <unk> steht neben einem Spielzeugpferd . <eos> <eos> <eos> <eos> <eos> <eos>\n","4 en : Three blond girls and a dark - haired girl try to sell decorated <unk> and rocks .\n","4 de : Mädchen Mädchen und ein dunkelhaariges Mädchen stehen , <unk> Muscheln und Steine zu verkaufen . <eos> <eos> <eos> <eos>\n","5 en : A group of people sit on the beach , beyond a sign warning of <unk> waves .\n","5 de : Gruppe von Menschen sitzt am Strand hinter einem Schild , das <unk> <unk> Wellen <unk> . <eos> <eos> <eos>\n","6 en : A man in sunglasses is writing on a pad with his bike leaned up against him .\n","6 de : Mann mit Sonnenbrille fährt auf einem roten , neben ihm steht an ihn angelehnt sein Fahrrad . <eos> <eos>\n","7 en : A guy with a pink shirt sitting on the ground , drawing a peacock with chalk .\n","7 de : Mann mit pinkfarbenem Hemd sitzt auf dem Boden und malt mit Kreide einen Pfau . <eos> <eos> <eos> <eos>\n","8 en : A man and a woman in bathing suits hold each other in a body of water .\n","8 de : Mann und eine Frau in Badekleidung halten einander in einem Gewässer . <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n","9 en : A woman holds a \" car wash \" sign on the edge of a quiet street .\n","9 de : Frau hält ein „ <unk> <unk> am Rand einer ruhigen Straße . <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n","Eval Loss : 0.4389058361151095\n","EPOCH[61] Train Loss : 0.8375840193238752\n","EPOCH[62] Train Loss : 0.7938138263492749\n","EPOCH[63] Train Loss : 0.823070533984694\n","EPOCH[64] Train Loss : 0.8818703439728967\n","EPOCH[65] Train Loss : 0.9249154343687255\n","EPOCH[66] Train Loss : 0.876641551585033\n","EPOCH[67] Train Loss : 0.8974201361680852\n","EPOCH[68] Train Loss : 0.860749378286559\n","EPOCH[69] Train Loss : 0.8396391199066722\n","EPOCH[70] Train Loss : 0.8439625293530267\n","Eval\n","0 en : A woman in a blue top and hat is stretching or performing yoga on the beach .\n","0 de : Frau in Hut in einem blauem Oberteil macht am Strand oder oder Stretching . <eos> <eos> mit mit mit\n","1 en : A young man in odd clothes leaning against a brick wall with a garden in it .\n","1 de : junger Mann in <unk> Kleidung lehnt an einer Ziegelmauer , die einen Garten umgibt . <eos> <eos> Ein Ein\n","2 en : Two men are looking toward the ground while one is wearing gloves and holding a tool .\n","2 de : Männer und und Boden , die von ihnen Handschuhe Handschuhe und hält ein Werkzeug . <eos> <eos> Weizen Weizen\n","3 en : A young child with a gray shirt and pacifier is standing next to a toy horse .\n","3 de : kleines Kind mit einem grauen Hemd und <unk> steht neben einem Spielzeugpferd . <eos> <eos> Ein Ein Ein Ein\n","4 en : Three blond girls and a dark - haired girl try to sell decorated <unk> and rocks .\n","4 de : Frauen Mädchen und ein dunkelhaariges Mädchen versuchen , <unk> Muscheln und sind zu verkaufen . <eos> <eos> indische indische\n","5 en : A group of people sit on the beach , beyond a sign warning of <unk> waves .\n","5 de : Gruppe von Menschen sitzt am hinter hinter einem Schild , das vor <unk> Wellen <unk> . <eos> <eos> Weizen\n","6 en : A man in sunglasses is writing on a pad with his bike leaned up against him .\n","6 de : Mann mit Sonnenbrille fährt auf einem langen , blickt ihm steht an ihn hinter sein Fahrrad . <eos> <eos>\n","7 en : A guy with a pink shirt sitting on the ground , drawing a peacock with chalk .\n","7 de : Mann mit pinkfarbenem Hemd sitzt auf dem Boden und mit mit Kreide einen Pfau . <eos> <eos> Ein Ein\n","8 en : A man and a woman in bathing suits hold each other in a body of water .\n","8 de : Mann und eine Frau in Badekleidung halten einander in einem Gewässer . <eos> <eos> lächelnd lächelnd lächelnd lächelnd lächelnd\n","9 en : A woman holds a \" car wash \" sign on the edge of a quiet street .\n","9 de : Frau hält ein <unk> <unk> <unk> am Rand einer ruhigen Straße . <eos> <eos> Ein Ein Ein Ein Ein\n","Eval Loss : 0.4198802546180528\n","EPOCH[71] Train Loss : 0.7763502859863741\n","EPOCH[72] Train Loss : 0.8119789630174636\n","EPOCH[73] Train Loss : 0.8214611425481994\n","EPOCH[74] Train Loss : 0.8895498599471717\n","EPOCH[75] Train Loss : 0.8348341846774364\n","EPOCH[76] Train Loss : 0.8731913304534452\n","EPOCH[77] Train Loss : 0.7625118654349755\n","EPOCH[78] Train Loss : 0.8219414291710689\n","EPOCH[79] Train Loss : 0.9545980054756691\n","EPOCH[80] Train Loss : 0.8897436135801776\n","Eval\n","0 en : A woman in a blue top and hat is stretching or performing yoga on the beach .\n","0 de : Frau mit einem in einem rosa Oberteil am am Strand Yoga oder Kinder . <eos> <eos> Ein Ein Ein\n","1 en : A young man in odd clothes leaning against a brick wall with a garden in it .\n","1 de : junger Mann in <unk> Kleidung lehnt an einer Ziegelmauer , die einen Plastikflaschen umgibt . <eos> <eos> Ein Ein\n","2 en : Two men are looking toward the ground while one is wearing gloves and holding a tool .\n","2 de : Männer und sich Boden , einer von ihnen trägt Handschuhe und hält ein Feuer . <eos> <eos> Ein Ein\n","3 en : A young child with a gray shirt and pacifier is standing next to a toy horse .\n","3 de : kleines Kind mit einem grauen Hemd steht steht steht neben einem Spielzeugpferd . <eos> <eos> Ein Ein Ein Ein\n","4 en : Three blond girls and a dark - haired girl try to sell decorated <unk> and rocks .\n","4 de : Personen Mädchen und ein dunkelhaariges Mädchen machen , <unk> Muscheln und Steine zu verkaufen . <eos> <eos> Ein Ein\n","5 en : A group of people sit on the beach , beyond a sign warning of <unk> waves .\n","5 de : Gruppe von Menschen sitzt am Strand hinter einem Schild , das <unk> <unk> Wellen <unk> . <eos> <eos> Ein\n","6 en : A man in sunglasses is writing on a pad with his bike leaned up against him .\n","6 de : Mann mit Sonnenbrille auf auf einem Bandana neben neben ihm steht an ihn des sein Fahrrad . <eos> <eos>\n","7 en : A guy with a pink shirt sitting on the ground , drawing a peacock with chalk .\n","7 de : Mann mit einer Hemd sitzt auf dem Boden und malt mit Kreide einen Pfau . <eos> <eos> Ein Ein\n","8 en : A man and a woman in bathing suits hold each other in a body of water .\n","8 de : Mann und eine Frau in Badekleidung halten einander in einem Gewässer . <eos> <eos> Ein Ein Ein Ein Ein\n","9 en : A woman holds a \" car wash \" sign on the edge of a quiet street .\n","9 de : Frau hält ein <unk> <unk> <unk> am Rand einer ruhigen Straße . <eos> <eos> Ein Ein Ein Ein Ein\n","Eval Loss : 0.37599703679182406\n","EPOCH[81] Train Loss : 0.8904226027686021\n","EPOCH[82] Train Loss : 0.7572262214689419\n","EPOCH[83] Train Loss : 0.7367252900682647\n","EPOCH[84] Train Loss : 0.7921656556170562\n","EPOCH[85] Train Loss : 0.7631677980053013\n","EPOCH[86] Train Loss : 0.888805161313764\n","EPOCH[87] Train Loss : 0.7970325522895517\n","EPOCH[88] Train Loss : 0.733949748863434\n","EPOCH[89] Train Loss : 0.8029597590195722\n","EPOCH[90] Train Loss : 0.8501973275480599\n","Eval\n","0 en : A woman in a blue top and hat is stretching or performing yoga on the beach .\n","0 de : Frau in einem in einem blauem Oberteil macht am Strand Yoga oder Stretching . <eos> <eos> Frau Frau Frau\n","1 en : A young man in odd clothes leaning against a brick wall with a garden in it .\n","1 de : Mann Mann in <unk> Kleidung lehnt an einer Ziegelmauer , die einen Garten umgibt . <eos> <eos> Frau Frau\n","2 en : Two men are looking toward the ground while one is wearing gloves and holding a tool .\n","2 de : Männer und und Boden , einer von ihnen trägt Handschuhe und hält ein Werkzeug . <eos> <eos> Frau Frau\n","3 en : A young child with a gray shirt and pacifier is standing next to a toy horse .\n","3 de : kleines Kind mit einem grauen Hemd und <unk> steht neben einem Spielzeugpferd . <eos> <eos> Frau Frau Frau Frau\n","4 en : Three blond girls and a dark - haired girl try to sell decorated <unk> and rocks .\n","4 de : Mädchen Mädchen und ein dunkelhaariges Mädchen versuchen , <unk> Muscheln und gefällten zu verkaufen . <eos> <eos> Frau Frau\n","5 en : A group of people sit on the beach , beyond a sign warning of <unk> waves .\n","5 de : Gruppe von Menschen sitzt am Strand hinter einem Schild , das vor <unk> Parkplatz <unk> . <eos> <eos> Weg\n","6 en : A man in sunglasses is writing on a pad with his bike leaned up against him .\n","6 de : Mann mit Sonnenbrille steht auf einem langen , neben ihm steht an ihn Bild sein Fahrrad . <eos> <eos>\n","7 en : A guy with a pink shirt sitting on the ground , drawing a peacock with chalk .\n","7 de : Mann mit pinkfarbenem Hemd sitzt auf dem Boden und malt mit Kreide einen Pfau . <eos> <eos> Frau Frau\n","8 en : A man and a woman in bathing suits hold each other in a body of water .\n","8 de : Mann und eine Frau in Badekleidung halten einander in einem Gewässer . <eos> <eos> Ein Ein Ein Ein Ein\n","9 en : A woman holds a \" car wash \" sign on the edge of a quiet street .\n","9 de : Frau hält ein „ <unk> <unk> am Rand einer ruhigen Straße . <eos> <eos> Frau Frau Frau Frau Frau\n","Eval Loss : 0.27243036558401995\n","EPOCH[91] Train Loss : 0.7591192584613274\n","EPOCH[92] Train Loss : 0.8386376013529712\n","EPOCH[93] Train Loss : 0.8083846963685134\n","EPOCH[94] Train Loss : 0.8362715156427745\n","EPOCH[95] Train Loss : 0.6787969836900974\n","EPOCH[96] Train Loss : 0.6353686453453425\n","EPOCH[97] Train Loss : 0.6655457639488681\n","EPOCH[98] Train Loss : 0.7064405701797584\n","EPOCH[99] Train Loss : 0.7093754084459667\n"]}],"source":["learning_rate = 0.001\n","max_lr = 0.1\n","epoch = 100\n","\n","model = Transformer(src_vocab_size=en_vocab_size, tgt_vocab_size=de_vocab_size, max_len=256, d_embed=512, n_layer=6, d_model=512, h=8, d_ff=2048).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n","scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr = max_lr, steps_per_epoch=int(len(multi_train_dataset)/batch_size), epochs = epoch)\n","criterion = torch.nn.CrossEntropyLoss(ignore_index=language_preprocess.pad_token_id)\n","\n","train(model, train_loader, optimizer, scheduler, criterion, epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZqlLtP8CUvVA"},"outputs":[],"source":["torch.save(model, \"model.pth\")\n","model = torch.load(\"model.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6253,"status":"ok","timestamp":1675396066007,"user":{"displayName":"박민수","userId":"02095835357899527286"},"user_tz":-540},"id":"dLWmVmrBUv2B","outputId":"e8a2d70d-170f-4d43-9fa0-8c4015cb3ce0"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 en : A barefoot boy with a blue and white striped towel is standing on the beach . <pad> <pad>\n","0 gt : Ein barfüßiger Junge mit einem blau-weiß gestreiften Handtuch steht am Strand . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n","0 de : Junge Junge mit einem blau-weiß gestreiften T-Shirt steht am Strand . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n","1 en : A uniformed man in the Army is training a German Shepherd using an arm guard . <pad> <pad>\n","1 gt : Ein uniformierter Mann von der Armee trainiert einen <unk> Schäferhund mit einem <unk> . <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n","1 de : Mann Mann , der trainiert trainiert einen <unk> stehen mit einem <unk> . <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n","2 en : A young woman in a pink shirt attempting to rope a calf at the rodeo . <pad> <pad>\n","2 gt : Eine junge Frau in einem pinkfarbenen Shirt versucht bei einem Rodeo , ein Kalb einzufangen . <eos> <pad> <pad> <pad> <pad>\n","2 de : Frau Frau in einem pinkfarbenen versucht versucht bei einem leeren , ein Kalb hoch . <eos> <eos> <eos> <eos> <eos>\n","3 en : An older male in blue jeans and brown coat is resting against an orange building . <pad> <pad>\n","3 gt : Ein älterer Mann in Bluejeans und brauner Jacke lehnt an einem orangen Gebäude . <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n","3 de : älterer Mann in <unk> und Jacke Jacke lehnt an einem orangen Gebäude . <eos> <eos> Ein Ein Ein Ein Ein\n","4 en : An older man with tattoos and biker <unk> <unk> a moment on a city street . <pad> <pad>\n","4 gt : Ein älterer Mann mit Tätowierungen und <unk> schlendert auf einer Straße in der Stadt herum . <eos> <pad> <pad> <pad> <pad>\n","4 de : Mann Herr mit blauem und <unk> schlendert auf einer Straße in der Stadt herum . <eos> <eos> Ein Ein Ein\n","5 en : A boy with glasses wearing a bright yellow shirt is standing in a parking lot . <pad> <pad>\n","5 gt : Ein Junge mit Brille und einem leuchtend gelben T-Shirt steht auf einem Parkplatz . <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n","5 de : Junge mit Brille und einem leuchtend gelben T-Shirt steht auf einem Parkplatz . <eos> <eos> Ein Ein Ein Ein Ein\n","6 en : A man wearing a bright , multi - color helmet is sitting on a motorcycle . <pad> <pad>\n","6 gt : Ein Mann mit einem leuchtend bunten Helm sitzt auf einem Motorrad . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n","6 de : Mann mit einem schwarzen bunten Helm sitzt auf einem Motorrad . <eos> <eos> Ein Ein Ein Ein Ein Ein Ein\n","7 en : A woman in a striped shirt <unk> her arms while standing in a grocery store . <pad> <pad>\n","7 gt : Eine Frau in einem gestreiften Shirt <unk> die Arme , während sie in einem Lebensmittelgeschäft steht . <eos> <pad> <pad> <pad>\n","7 de : Frau in einem <unk> <unk> <unk> , Arme , während sie in einem Star steht . <eos> <eos> <eos> <eos>\n","8 en : A woman in a restaurant is drinking out of a coconut , using a straw . <pad> <pad>\n","8 gt : Eine Frau in einem Restaurant trinkt mit einem Strohhalm aus einer <unk> . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n","8 de : Frau in einem Schreibtisch , mit einem leger aus einer <unk> . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n","9 en : A young helmeted biker in blue takes to the air while going over small hills . <pad> <pad>\n","9 gt : Ein junger , <unk> Fahrradfahrer in Blau wird bei der Fahrt über kleine Hügel in die Luft getragen . <eos> <pad>\n","9 de : junger , <unk> in in Blau wird bei der Nachbarschaft über kleine Jungen in die Luft herum . <eos> <eos>\n","0.9506050998514349\n","0 en : A woman in a blue top and hat is stretching or performing yoga on the beach .\n","0 gt : Eine Frau mit Hut in einem blauem Oberteil macht am Strand Yoga oder Stretching . <eos> <pad> <pad> <pad> <pad>\n","0 de : Frau mit Hut in einem Park Oberteil macht am Strand oder oder Stretching . <eos> <eos> <eos> <eos> <eos>\n","1 en : A young man in odd clothes leaning against a brick wall with a garden in it .\n","1 gt : Ein junger Mann in <unk> Kleidung lehnt an einer Ziegelmauer , die einen Garten umgibt . <eos> <pad> <pad> <pad>\n","1 de : Mann Mann in <unk> Kleidung lehnt an einer Ziegelmauer , die einen Garten umgibt . <eos> <eos> Ein Ein\n","2 en : Two men are looking toward the ground while one is wearing gloves and holding a tool .\n","2 gt : Zwei Männer schauen zum Boden , einer von ihnen trägt Handschuhe und hält ein Werkzeug . <eos> <pad> <pad> <pad>\n","2 de : Männer schauen , Boden , einer von ihnen für Handschuhe und hält ein Feuer . <eos> <eos> <eos> <eos>\n","3 en : A young child with a gray shirt and pacifier is standing next to a toy horse .\n","3 gt : Ein kleines Kind mit einem grauen Hemd und <unk> steht neben einem Spielzeugpferd . <eos> <pad> <pad> <pad> <pad> <pad>\n","3 de : kleines Mädchen mit einem grauen Hemd und <unk> steht neben einem Spielzeugpferd . <eos> <eos> Ein Ein Ein Ein\n","4 en : Three blond girls and a dark - haired girl try to sell decorated <unk> and rocks .\n","4 gt : Drei blonde Mädchen und ein dunkelhaariges Mädchen versuchen , <unk> Muscheln und Steine zu verkaufen . <eos> <pad> <pad> <pad>\n","4 de : blonde Mädchen und ein dunkelhaariges Mädchen versuchen , <unk> Muscheln und Steine zu verkaufen . <eos> <eos> <eos> <eos>\n","5 en : A group of people sit on the beach , beyond a sign warning of <unk> waves .\n","5 gt : Eine Gruppe von Menschen sitzt am Strand hinter einem Schild , das vor <unk> Wellen <unk> . <eos> <pad> <pad>\n","5 de : Gruppe von Personen sitzt am Strand hinter einem Boot , das vor <unk> Wellen <unk> . <eos> <eos> Ein\n","6 en : A man in sunglasses is writing on a pad with his bike leaned up against him .\n","6 gt : Ein Mann mit Sonnenbrille schreibt auf einem Block , neben ihm steht an ihn angelehnt sein Fahrrad . <eos> <pad>\n","6 de : Mann mit Sonnenbrille legt auf einem langen , neben ihm steht an seinem angelehnt sein Fahrrad . <eos> <eos>\n","7 en : A guy with a pink shirt sitting on the ground , drawing a peacock with chalk .\n","7 gt : Ein Mann mit pinkfarbenem Hemd sitzt auf dem Boden und malt mit Kreide einen Pfau . <eos> <pad> <pad> <pad>\n","7 de : Mann mit pinkfarbenem Hemd sitzt auf dem Boden und malt mit Kreide einen <unk> . <eos> <eos> Ein Ein\n","8 en : A man and a woman in bathing suits hold each other in a body of water .\n","8 gt : Ein Mann und eine Frau in Badekleidung halten einander in einem Gewässer . <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n","8 de : Mann und eine Frau in Badekleidung halten einander in einem Gewässer . <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n","9 en : A woman holds a \" car wash \" sign on the edge of a quiet street .\n","9 gt : Eine Frau hält ein „ <unk> <unk> am Rand einer ruhigen Straße . <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n","9 de : Frau hält ein „ <unk> <unk> am Rand einer ruhigen Straße . <eos> <eos> Ein Ein Ein Ein Ein\n","0.3010826259080706\n"]}],"source":["\n","seq_lengths = list(map(lambda x: (len(x[0]), len(x[1])), multi_val_dataset))\n","batch_sampler = batch_sampling(seq_lengths, batch_size)\n","val_loader = torch.utils.data.DataLoader(multi_val_dataset, collate_fn=collate_fn, batch_sampler=batch_sampler)\n","\n","eval_loss = eval(model, val_loader, criterion, True)\n","print(eval_loss)\n","eval_loss = eval(model, train_loader, criterion, True)\n","print(eval_loss)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1H59JZRefiLJ2Ku8ZpB63b9EK8kEKPV1-","timestamp":1675396184449}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
