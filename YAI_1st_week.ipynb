{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YAI 1st week Assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Consider the neural network with initialized weights $ w1 = 1.5 , w2 = 2.5 , w3 = 2, w4 = 1, w5 = 2 , w6 = 1.5 $ . We are using the sigmoid activation functions between layers. We use the input values with $ i1 =1, i2 =1 $ and the target values as $ y1 = 0.7, y2 =0.5 $ . We will use learning rate $\\gamma = 0.5 $ . For this problem, we will calculate 1-time (1 iteration of) backpropagation update. Assume that there is no bias term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://i.ibb.co/c1DdgTX/1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (a) Calculate the h1, h2, o1, o2 and the total error using $ E = 1/2*[(o1 − y1)^2 + (o2 − y2)^2] $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: 1 - (a)\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (b) Calculate $ ∂E/∂w4 $ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: 1 - (b)\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (c) Calculate $ ∂E/∂w1 $ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: 1 - (c)\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (d) Using results in (b), (c) update $ w1, w4 $ through the 1-time backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: 1 - (d)\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-VZ7UK9Op6x"
   },
   "source": [
    "## Question 2\n",
    "\n",
    "Fill the blanks of code cells \n",
    "\n",
    "In this task, you will implement the following to train a MLP:\n",
    "1. forward pass\n",
    "2. backward pass\n",
    "3. weights update\n",
    "\n",
    "The MLP has an input layer, one hidden layer, and one output layer.\n",
    "\n",
    "The input layer, the hidden layer, and the output layer has 784 nodes, 128 nodes, and 10 nodes, respectively.\n",
    "\n",
    "You can use only the given `sigmoid` function as activation function, and `sigmoid_prime` function as its derivative.\n",
    "\n",
    "You cannot use library functions except:\n",
    "- [`torch.add`](https://pytorch.org/docs/stable/generated/torch.add.html)\n",
    "- [`torch.mul`](https://pytorch.org/docs/stable/generated/torch.mul.html)\n",
    "- [`torch.transpose`](https://pytorch.org/docs/stable/generated/torch.transpose.html)\n",
    "- [`torch.mm`](https://pytorch.org/docs/stable/generated/torch.mm.html)\n",
    "- [`torch.sum`](https://pytorch.org/docs/stable/generated/torch.sum.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssH-DKB8Ihv0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import math\n",
    "\n",
    "def iterate(iterable):\n",
    "    from tqdm.notebook import tqdm\n",
    "    return tqdm(iterable, total=len(iterable), leave=False)\n",
    "\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except ImportError:  # Try to install tqdm via pip\n",
    "    %pip install tqdm\n",
    "    try:\n",
    "        from tqdm.notebook import tqdm\n",
    "    except ImportError:  # Double-checked import failed\n",
    "        def iterate(iterable):  # fallback iterator which prints progress\n",
    "            length = len(iterable)\n",
    "            for i, data in enumerate(iterable):\n",
    "                if i % 10000 == 0:\n",
    "                    print(\"{0}/{1}\".format(i, length))\n",
    "                yield data\n",
    "\n",
    "torch.manual_seed(0x010727)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzp8BcKErmnG"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  # below code is same as: return torch.div(torch.tensor(1.0), torch.add(torch.tensor(1.0), torch.exp(torch.negative(x))))\n",
    "    return x.sigmoid()\n",
    "\n",
    "def sigmoid_prime(x):  # derivative of sigmoid\n",
    "    return torch.mul(sigmoid(x), sigmoid(torch.neg(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6XRFOzKJHha"
   },
   "outputs": [],
   "source": [
    "train_MNIST = datasets.MNIST(\"MNIST_data/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_MNIST, shuffle=True, drop_last=True)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "dtype = torch.float32\n",
    "D_in, H, D_out = 784, 128, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A weight and a bias for input nodes\n",
    "w1 = torch.randn(D_in, H).to(device, dtype) * math.sqrt(1. / D_in)\n",
    "b1 = torch.randn(1, H).to(device, dtype) * math.sqrt(1. / D_in)\n",
    "\n",
    "# A weight and a bias for hidden nodes\n",
    "w2 = torch.randn(H, D_out).to(device, dtype) * math.sqrt(1. / H)\n",
    "b2 = torch.randn(1, D_out).to(device, dtype) * math.sqrt(1. / H)\n",
    "\n",
    "learning_rate = 0.1  # you can fix the learning rate\n",
    "epochs = 5  # you can fix the epochs\n",
    "\n",
    "# we will not call .requires_grad_() to set gradient enabled for each weights, \n",
    "# since we will calculate each gradient manually in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0rfQnmSuOlw"
   },
   "source": [
    "Refer to the following equation to implement forward pass: $(x = input, a_2 = prediction)$\n",
    "\n",
    "\n",
    "$$ z_1 = W_1 x + b_1 $$\n",
    "$$ a_1 = \\sigma(z_1) $$\n",
    "$$ z_2 = W_2 a_1 + b_2 $$\n",
    "$$ a_2 = \\sigma(z_2) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-z6SRbEivhpq"
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs): \n",
    "    corrects = 0\n",
    "    for x, y in iterate(train_loader):\n",
    "        x = x.view((1,784)).to(device, dtype)\n",
    "        y = y.to(device)\n",
    "        y_onehot = torch.zeros((1,10)).to(device, dtype)\n",
    "        y_onehot[0, y] += 1.\n",
    "        \n",
    "        ############################################################################\n",
    "        # TODO: Implement the forward pass for the two-layer net                   #\n",
    "        #                                                                          #\n",
    "        ############################################################################\n",
    "\n",
    "        z1 = \n",
    "        a1 = \n",
    "        z2 = \n",
    "        a2 = \n",
    "\n",
    "        ############################################################################\n",
    "        #                             END OF YOUR CODE                             #\n",
    "        ############################################################################\n",
    "\n",
    "        diff = a2 - y_onehot # -(y_onehot-a2)\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Implement the backword pass for the two-layer net and update the   #\n",
    "        # parameters                                                               #\n",
    "        ############################################################################\n",
    "\n",
    "        # backward pass\n",
    "        d_z2 = \n",
    "        d_b2 = \n",
    "        d_w2 = \n",
    "\n",
    "        d_a1 = \n",
    "        d_z1 = \n",
    "        d_b1 = \n",
    "        d_w1 = \n",
    "\n",
    "        # weight update\n",
    "        w1 -= \n",
    "        b1 -= \n",
    "        w2 -= \n",
    "        b2 -= \n",
    "\n",
    "        ############################################################################\n",
    "        #                             END OF YOUR CODE                             #\n",
    "        ############################################################################\n",
    "\n",
    "        if torch.argmax(a2) == y:\n",
    "            corrects += 1\n",
    "     \n",
    "    print(\"Epoch {}, Accuracy: {:.3f}\".format(epoch+1, corrects/len(train_MNIST))) \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "YAI_1st_week.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
