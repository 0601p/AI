{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-1 Multivariable Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 80],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "optimizer = torch.optim.SGD([W, b], lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1/20 hypothesis: tensor([0., 0., 0., 0., 0.]), Cost: 29661.800781\n",
      "Epoch    2/20 hypothesis: tensor([66.7178, 80.1701, 76.1025, 86.0194, 61.1565]), Cost: 9537.694336\n",
      "Epoch    3/20 hypothesis: tensor([104.5421, 125.6208, 119.2478, 134.7862,  95.8280]), Cost: 3069.590088\n",
      "Epoch    4/20 hypothesis: tensor([125.9858, 151.3882, 143.7087, 162.4333, 115.4844]), Cost: 990.670288\n",
      "Epoch    5/20 hypothesis: tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]), Cost: 322.481873\n",
      "Epoch    6/20 hypothesis: tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]), Cost: 107.717064\n",
      "Epoch    7/20 hypothesis: tensor([148.9423, 178.9730, 169.8976, 192.0301, 136.5279]), Cost: 38.687496\n",
      "Epoch    8/20 hypothesis: tensor([151.1574, 181.6346, 172.4254, 194.8856, 138.5585]), Cost: 16.499043\n",
      "Epoch    9/20 hypothesis: tensor([152.4131, 183.1435, 173.8590, 196.5043, 139.7097]), Cost: 9.365656\n",
      "Epoch   10/20 hypothesis: tensor([153.1250, 183.9988, 174.6723, 197.4217, 140.3625]), Cost: 7.071114\n",
      "Epoch   11/20 hypothesis: tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]), Cost: 6.331847\n",
      "Epoch   12/20 hypothesis: tensor([153.7572, 184.7582, 175.3958, 198.2360, 140.9424]), Cost: 6.092532\n",
      "Epoch   13/20 hypothesis: tensor([153.8868, 184.9138, 175.5449, 198.4026, 141.0613]), Cost: 6.013817\n",
      "Epoch   14/20 hypothesis: tensor([153.9602, 185.0019, 175.6299, 198.4969, 141.1288]), Cost: 5.986785\n",
      "Epoch   15/20 hypothesis: tensor([154.0017, 185.0517, 175.6785, 198.5500, 141.1671]), Cost: 5.976325\n",
      "Epoch   16/20 hypothesis: tensor([154.0252, 185.0798, 175.7065, 198.5800, 141.1888]), Cost: 5.971208\n",
      "Epoch   17/20 hypothesis: tensor([154.0385, 185.0956, 175.7229, 198.5966, 141.2012]), Cost: 5.967835\n",
      "Epoch   18/20 hypothesis: tensor([154.0459, 185.1045, 175.7326, 198.6059, 141.2082]), Cost: 5.964969\n",
      "Epoch   19/20 hypothesis: tensor([154.0501, 185.1094, 175.7386, 198.6108, 141.2122]), Cost: 5.962291\n",
      "Epoch   20/20 hypothesis: tensor([154.0524, 185.1120, 175.7424, 198.6134, 141.2145]), Cost: 5.959664\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "    cost = torch.mean((y_train - hypothesis) ** 2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} hypothesis: {}, Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(3, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = MultivariateLinearRegressionModel()\n",
    "\n",
    "# 강의랑 조금 다른데 이게 맞는거같음\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5)\n",
    "nb_epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1/20 hypothesis: tensor([ 1.8503, -1.6247, -0.2303,  0.4519, -2.1785]), Cost: 29776.636719\n",
      "Epoch    2/20 hypothesis: tensor([68.6909, 78.6940, 76.0125, 86.6301, 59.0916]), Cost: 9578.069336\n",
      "Epoch    3/20 hypothesis: tensor([106.5846, 124.2292, 119.2373, 135.4870,  93.8277]), Cost: 3086.030762\n",
      "Epoch    4/20 hypothesis: tensor([128.0674, 150.0445, 143.7431, 163.1851, 113.5210]), Cost: 999.417847\n",
      "Epoch    5/20 hypothesis: tensor([140.2464, 164.6801, 157.6365, 178.8878, 124.6859]), Cost: 328.755310\n",
      "Epoch    6/20 hypothesis: tensor([147.1508, 172.9775, 165.5134, 187.7898, 131.0159]), Cost: 113.194664\n",
      "Epoch    7/20 hypothesis: tensor([151.0648, 177.6816, 169.9795, 192.8363, 134.6049]), Cost: 43.908276\n",
      "Epoch    8/20 hypothesis: tensor([153.2834, 180.3486, 172.5117, 195.6971, 136.6398]), Cost: 21.636120\n",
      "Epoch    9/20 hypothesis: tensor([154.5410, 181.8606, 173.9477, 197.3186, 137.7937]), Cost: 14.474878\n",
      "Epoch   10/20 hypothesis: tensor([155.2536, 182.7179, 174.7621, 198.2376, 138.4482]), Cost: 12.170435\n",
      "Epoch   11/20 hypothesis: tensor([155.6573, 183.2039, 175.2242, 198.7583, 138.8194]), Cost: 11.427031\n",
      "Epoch   12/20 hypothesis: tensor([155.8859, 183.4795, 175.4864, 199.0533, 139.0302]), Cost: 11.185369\n",
      "Epoch   13/20 hypothesis: tensor([156.0152, 183.6359, 175.6355, 199.2202, 139.1499]), Cost: 11.104920\n",
      "Epoch   14/20 hypothesis: tensor([156.0883, 183.7245, 175.7203, 199.3145, 139.2180]), Cost: 11.076324\n",
      "Epoch   15/20 hypothesis: tensor([156.1293, 183.7748, 175.7687, 199.3677, 139.2569]), Cost: 11.064394\n",
      "Epoch   16/20 hypothesis: tensor([156.1524, 183.8034, 175.7965, 199.3975, 139.2792]), Cost: 11.057844\n",
      "Epoch   17/20 hypothesis: tensor([156.1651, 183.8197, 175.8126, 199.4142, 139.2921]), Cost: 11.052947\n",
      "Epoch   18/20 hypothesis: tensor([156.1721, 183.8289, 175.8221, 199.4233, 139.2997]), Cost: 11.048703\n",
      "Epoch   19/20 hypothesis: tensor([156.1757, 183.8342, 175.8278, 199.4282, 139.3042]), Cost: 11.044532\n",
      "Epoch   20/20 hypothesis: tensor([156.1775, 183.8373, 175.8313, 199.4306, 139.3070]), Cost: 11.040511\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, nb_epochs + 1):\n",
    "    hypothesis = model(x_train)\n",
    "    cost = torch.nn.functional.mse_loss(hypothesis, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} hypothesis: {}, Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
