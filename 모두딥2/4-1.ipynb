{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-1 Multivariable Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 80],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "optimizer = torch.optim.SGD([W, b], lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1/20 hypothesis: tensor([0., 0., 0., 0., 0.]), Cost: 29661.800781\n",
      "Epoch    2/20 hypothesis: tensor([66.7178, 80.1701, 76.1025, 86.0194, 61.1565]), Cost: 9537.694336\n",
      "Epoch    3/20 hypothesis: tensor([104.5421, 125.6208, 119.2478, 134.7862,  95.8280]), Cost: 3069.590088\n",
      "Epoch    4/20 hypothesis: tensor([125.9858, 151.3882, 143.7087, 162.4333, 115.4844]), Cost: 990.670288\n",
      "Epoch    5/20 hypothesis: tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]), Cost: 322.481873\n",
      "Epoch    6/20 hypothesis: tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]), Cost: 107.717064\n",
      "Epoch    7/20 hypothesis: tensor([148.9423, 178.9730, 169.8976, 192.0301, 136.5279]), Cost: 38.687496\n",
      "Epoch    8/20 hypothesis: tensor([151.1574, 181.6346, 172.4254, 194.8856, 138.5585]), Cost: 16.499043\n",
      "Epoch    9/20 hypothesis: tensor([152.4131, 183.1435, 173.8590, 196.5043, 139.7097]), Cost: 9.365656\n",
      "Epoch   10/20 hypothesis: tensor([153.1250, 183.9988, 174.6723, 197.4217, 140.3625]), Cost: 7.071114\n",
      "Epoch   11/20 hypothesis: tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]), Cost: 6.331847\n",
      "Epoch   12/20 hypothesis: tensor([153.7572, 184.7582, 175.3958, 198.2360, 140.9424]), Cost: 6.092532\n",
      "Epoch   13/20 hypothesis: tensor([153.8868, 184.9138, 175.5449, 198.4026, 141.0613]), Cost: 6.013817\n",
      "Epoch   14/20 hypothesis: tensor([153.9602, 185.0019, 175.6299, 198.4969, 141.1288]), Cost: 5.986785\n",
      "Epoch   15/20 hypothesis: tensor([154.0017, 185.0517, 175.6785, 198.5500, 141.1671]), Cost: 5.976325\n",
      "Epoch   16/20 hypothesis: tensor([154.0252, 185.0798, 175.7065, 198.5800, 141.1888]), Cost: 5.971208\n",
      "Epoch   17/20 hypothesis: tensor([154.0385, 185.0956, 175.7229, 198.5966, 141.2012]), Cost: 5.967835\n",
      "Epoch   18/20 hypothesis: tensor([154.0459, 185.1045, 175.7326, 198.6059, 141.2082]), Cost: 5.964969\n",
      "Epoch   19/20 hypothesis: tensor([154.0501, 185.1094, 175.7386, 198.6108, 141.2122]), Cost: 5.962291\n",
      "Epoch   20/20 hypothesis: tensor([154.0524, 185.1120, 175.7424, 198.6134, 141.2145]), Cost: 5.959664\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "    cost = torch.mean((y_train - hypothesis) ** 2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} hypothesis: {}, Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(3, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = MultivariateLinearRegressionModel()\n",
    "\n",
    "# 강의랑 조금 다른데 이게 맞는거같음\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5)\n",
    "nb_epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1/20 hypothesis: tensor([101.8534, 121.2482, 114.8841, 130.9526,  91.9971]), Cost: 3510.101074\n",
      "Epoch    2/20 hypothesis: tensor([124.7786, 148.7960, 141.0351, 160.5099, 113.0118]), Cost: 1133.971313\n",
      "Epoch    3/20 hypothesis: tensor([137.7755, 164.4137, 155.8614, 177.2666, 124.9258]), Cost: 370.255463\n",
      "Epoch    4/20 hypothesis: tensor([145.1437, 173.2676, 164.2673, 186.7662, 131.6802]), Cost: 124.787209\n",
      "Epoch    5/20 hypothesis: tensor([149.3208, 178.2871, 169.0334, 192.1515, 135.5097]), Cost: 45.888538\n",
      "Epoch    6/20 hypothesis: tensor([151.6888, 181.1328, 171.7360, 195.2043, 137.6808]), Cost: 20.527105\n",
      "Epoch    7/20 hypothesis: tensor([153.0312, 182.7459, 173.2686, 196.9347, 138.9117]), Cost: 12.373555\n",
      "Epoch    8/20 hypothesis: tensor([153.7921, 183.6604, 174.1380, 197.9155, 139.6097]), Cost: 9.750433\n",
      "Epoch    9/20 hypothesis: tensor([154.2233, 184.1787, 174.6313, 198.4712, 140.0054]), Cost: 8.905085\n",
      "Epoch   10/20 hypothesis: tensor([154.4677, 184.4725, 174.9115, 198.7859, 140.2299]), Cost: 8.631021\n",
      "Epoch   11/20 hypothesis: tensor([154.6060, 184.6390, 175.0708, 198.9641, 140.3572]), Cost: 8.540601\n",
      "Epoch   12/20 hypothesis: tensor([154.6844, 184.7332, 175.1617, 199.0648, 140.4295]), Cost: 8.509204\n",
      "Epoch   13/20 hypothesis: tensor([154.7286, 184.7866, 175.2136, 199.1216, 140.4706]), Cost: 8.496763\n",
      "Epoch   14/20 hypothesis: tensor([154.7536, 184.8167, 175.2436, 199.1535, 140.4939]), Cost: 8.490468\n",
      "Epoch   15/20 hypothesis: tensor([154.7676, 184.8337, 175.2610, 199.1713, 140.5073]), Cost: 8.486105\n",
      "Epoch   16/20 hypothesis: tensor([154.7755, 184.8433, 175.2714, 199.1810, 140.5149]), Cost: 8.482373\n",
      "Epoch   17/20 hypothesis: tensor([154.7798, 184.8486, 175.2778, 199.1863, 140.5193]), Cost: 8.478823\n",
      "Epoch   18/20 hypothesis: tensor([154.7821, 184.8515, 175.2819, 199.1890, 140.5219]), Cost: 8.475370\n",
      "Epoch   19/20 hypothesis: tensor([154.7832, 184.8531, 175.2847, 199.1902, 140.5235]), Cost: 8.471927\n",
      "Epoch   20/20 hypothesis: tensor([154.7838, 184.8538, 175.2868, 199.1906, 140.5245]), Cost: 8.468492\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, nb_epochs + 1):\n",
    "    hypothesis = model(x_train)\n",
    "    cost = torch.nn.functional.mse_loss(hypothesis, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} hypothesis: {}, Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
