{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0],  [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.Tensor(2, 2).to(device)\n",
    "b1 = torch.Tensor(2).to(device)\n",
    "w2 = torch.Tensor(2, 1).to(device)\n",
    "b2 = torch.Tensor(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + torch.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:    0, cost:0.6931471824645996\n",
      "step:  100, cost:0.6931471824645996\n",
      "step:  200, cost:0.6931471824645996\n",
      "step:  300, cost:0.6931471824645996\n",
      "step:  400, cost:0.6931471824645996\n",
      "step:  500, cost:0.6931471824645996\n",
      "step:  600, cost:0.6931471824645996\n",
      "step:  700, cost:0.6931471824645996\n",
      "step:  800, cost:0.6931471824645996\n",
      "step:  900, cost:0.6931471824645996\n",
      "step: 1000, cost:0.6931471824645996\n",
      "step: 1100, cost:0.6931471824645996\n",
      "step: 1200, cost:0.6931471824645996\n",
      "step: 1300, cost:0.6931471824645996\n",
      "step: 1400, cost:0.6931471824645996\n",
      "step: 1500, cost:0.6931471824645996\n",
      "step: 1600, cost:0.6931471824645996\n",
      "step: 1700, cost:0.6931471824645996\n",
      "step: 1800, cost:0.6931471824645996\n",
      "step: 1900, cost:0.6931471824645996\n",
      "step: 2000, cost:0.6931471824645996\n",
      "step: 2100, cost:0.6931471824645996\n",
      "step: 2200, cost:0.6931471824645996\n",
      "step: 2300, cost:0.6931471824645996\n",
      "step: 2400, cost:0.6931471824645996\n",
      "step: 2500, cost:0.6931471824645996\n",
      "step: 2600, cost:0.6931471824645996\n",
      "step: 2700, cost:0.6931471824645996\n",
      "step: 2800, cost:0.6931471824645996\n",
      "step: 2900, cost:0.6931471824645996\n",
      "step: 3000, cost:0.6931471824645996\n",
      "step: 3100, cost:0.6931471824645996\n",
      "step: 3200, cost:0.6931471824645996\n",
      "step: 3300, cost:0.6931471824645996\n",
      "step: 3400, cost:0.6931471824645996\n",
      "step: 3500, cost:0.6931471824645996\n",
      "step: 3600, cost:0.6931471824645996\n",
      "step: 3700, cost:0.6931471824645996\n",
      "step: 3800, cost:0.6931471824645996\n",
      "step: 3900, cost:0.6931471824645996\n",
      "step: 4000, cost:0.6931471824645996\n",
      "step: 4100, cost:0.6931471824645996\n",
      "step: 4200, cost:0.6931471824645996\n",
      "step: 4300, cost:0.6931471824645996\n",
      "step: 4400, cost:0.6931471824645996\n",
      "step: 4500, cost:0.6931471824645996\n",
      "step: 4600, cost:0.6931471824645996\n",
      "step: 4700, cost:0.6931471824645996\n",
      "step: 4800, cost:0.6931471824645996\n",
      "step: 4900, cost:0.6931471824645996\n",
      "step: 5000, cost:0.6931471824645996\n",
      "step: 5100, cost:0.6931471824645996\n",
      "step: 5200, cost:0.6931471824645996\n",
      "step: 5300, cost:0.6931471824645996\n",
      "step: 5400, cost:0.6931471824645996\n",
      "step: 5500, cost:0.6931471824645996\n",
      "step: 5600, cost:0.6931471824645996\n",
      "step: 5700, cost:0.6931471824645996\n",
      "step: 5800, cost:0.6931471824645996\n",
      "step: 5900, cost:0.6931471824645996\n",
      "step: 6000, cost:0.6931471824645996\n",
      "step: 6100, cost:0.6931471824645996\n",
      "step: 6200, cost:0.6931471824645996\n",
      "step: 6300, cost:0.6931471824645996\n",
      "step: 6400, cost:0.6931471824645996\n",
      "step: 6500, cost:0.6931471824645996\n",
      "step: 6600, cost:0.6931471824645996\n",
      "step: 6700, cost:0.6931471824645996\n",
      "step: 6800, cost:0.6931471824645996\n",
      "step: 6900, cost:0.6931471824645996\n",
      "step: 7000, cost:0.6931471824645996\n",
      "step: 7100, cost:0.6931471824645996\n",
      "step: 7200, cost:0.6931471824645996\n",
      "step: 7300, cost:0.6931471824645996\n",
      "step: 7400, cost:0.6931471824645996\n",
      "step: 7500, cost:0.6931471824645996\n",
      "step: 7600, cost:0.6931471824645996\n",
      "step: 7700, cost:0.6931471824645996\n",
      "step: 7800, cost:0.6931471824645996\n",
      "step: 7900, cost:0.6931471824645996\n",
      "step: 8000, cost:0.6931471824645996\n",
      "step: 8100, cost:0.6931471824645996\n",
      "step: 8200, cost:0.6931471824645996\n",
      "step: 8300, cost:0.6931471824645996\n",
      "step: 8400, cost:0.6931471824645996\n",
      "step: 8500, cost:0.6931471824645996\n",
      "step: 8600, cost:0.6931471824645996\n",
      "step: 8700, cost:0.6931471824645996\n",
      "step: 8800, cost:0.6931471824645996\n",
      "step: 8900, cost:0.6931471824645996\n",
      "step: 9000, cost:0.6931471824645996\n",
      "step: 9100, cost:0.6931471824645996\n",
      "step: 9200, cost:0.6931471824645996\n",
      "step: 9300, cost:0.6931471824645996\n",
      "step: 9400, cost:0.6931471824645996\n",
      "step: 9500, cost:0.6931471824645996\n",
      "step: 9600, cost:0.6931471824645996\n",
      "step: 9700, cost:0.6931471824645996\n",
      "step: 9800, cost:0.6931471824645996\n",
      "step: 9900, cost:0.6931471824645996\n",
      "step:10000, cost:0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1\n",
    "\n",
    "for step in range(10001):\n",
    "    #forward\n",
    "    l1 = X.matmul(w1) + b1\n",
    "    a1 = sigmoid(l1)\n",
    "    l2 = a1.matmul(w2) + b2\n",
    "    Y_pred = sigmoid(l2)\n",
    "    cost = -torch.mean(Y * torch.log(Y_pred) + (1 - Y) * torch.log(1 - Y_pred))\n",
    "    #back prop\n",
    "    d_Y_pred = (Y_pred - Y) / (Y_pred * (1.0 - Y_pred) + 1e-7)\n",
    "\n",
    "    d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
    "    d_b2 = d_l2\n",
    "    d_w2 = a1.transpose(0, 1).matmul(d_b2)\n",
    "\n",
    "    d_a1 = d_b2.matmul(w2.transpose(0, 1))\n",
    "    d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "    d_b1 = d_l1\n",
    "    d_w1 =X.transpose(0, 1).matmul(d_b1)\n",
    "\n",
    "    w1 = w1 - learning_rate * d_w1\n",
    "    b1 = b1 - learning_rate * d_b1.mean(0)\n",
    "    w2 = w2 - learning_rate * d_w2\n",
    "    b2 = b2 - learning_rate * d_b2.mean(0)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(\"step:{:5d}, cost:{}\".format(step, cost.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xor-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0],  [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:    0, cost:0.743407\n",
      "step:  100, cost:0.693165\n",
      "step:  200, cost:0.693158\n",
      "step:  300, cost:0.693152\n",
      "step:  400, cost:0.693146\n",
      "step:  500, cost:0.693141\n",
      "step:  600, cost:0.693136\n",
      "step:  700, cost:0.693130\n",
      "step:  800, cost:0.693122\n",
      "step:  900, cost:0.693113\n",
      "step: 1000, cost:0.693100\n",
      "step: 1100, cost:0.693082\n",
      "step: 1200, cost:0.693057\n",
      "step: 1300, cost:0.693019\n",
      "step: 1400, cost:0.692961\n",
      "step: 1500, cost:0.692866\n",
      "step: 1600, cost:0.692703\n",
      "step: 1700, cost:0.692396\n",
      "step: 1800, cost:0.691730\n",
      "step: 1900, cost:0.689965\n",
      "step: 2000, cost:0.683832\n",
      "step: 2100, cost:0.656167\n",
      "step: 2200, cost:0.431102\n",
      "step: 2300, cost:0.134893\n",
      "step: 2400, cost:0.066304\n",
      "step: 2500, cost:0.042168\n",
      "step: 2600, cost:0.030454\n",
      "step: 2700, cost:0.023666\n",
      "step: 2800, cost:0.019278\n",
      "step: 2900, cost:0.016224\n",
      "step: 3000, cost:0.013984\n",
      "step: 3100, cost:0.012274\n",
      "step: 3200, cost:0.010928\n",
      "step: 3300, cost:0.009842\n",
      "step: 3400, cost:0.008949\n",
      "step: 3500, cost:0.008201\n",
      "step: 3600, cost:0.007567\n",
      "step: 3700, cost:0.007022\n",
      "step: 3800, cost:0.006549\n",
      "step: 3900, cost:0.006134\n",
      "step: 4000, cost:0.005768\n",
      "step: 4100, cost:0.005443\n",
      "step: 4200, cost:0.005152\n",
      "step: 4300, cost:0.004890\n",
      "step: 4400, cost:0.004653\n",
      "step: 4500, cost:0.004437\n",
      "step: 4600, cost:0.004241\n",
      "step: 4700, cost:0.004061\n",
      "step: 4800, cost:0.003895\n",
      "step: 4900, cost:0.003742\n",
      "step: 5000, cost:0.003601\n",
      "step: 5100, cost:0.003469\n",
      "step: 5200, cost:0.003347\n",
      "step: 5300, cost:0.003233\n",
      "step: 5400, cost:0.003127\n",
      "step: 5500, cost:0.003027\n",
      "step: 5600, cost:0.002933\n",
      "step: 5700, cost:0.002845\n",
      "step: 5800, cost:0.002762\n",
      "step: 5900, cost:0.002684\n",
      "step: 6000, cost:0.002610\n",
      "step: 6100, cost:0.002539\n",
      "step: 6200, cost:0.002473\n",
      "step: 6300, cost:0.002410\n",
      "step: 6400, cost:0.002350\n",
      "step: 6500, cost:0.002293\n",
      "step: 6600, cost:0.002238\n",
      "step: 6700, cost:0.002186\n",
      "step: 6800, cost:0.002136\n",
      "step: 6900, cost:0.002089\n",
      "step: 7000, cost:0.002044\n",
      "step: 7100, cost:0.002000\n",
      "step: 7200, cost:0.001958\n",
      "step: 7300, cost:0.001918\n",
      "step: 7400, cost:0.001880\n",
      "step: 7500, cost:0.001843\n",
      "step: 7600, cost:0.001808\n",
      "step: 7700, cost:0.001773\n",
      "step: 7800, cost:0.001740\n",
      "step: 7900, cost:0.001709\n",
      "step: 8000, cost:0.001678\n",
      "step: 8100, cost:0.001649\n",
      "step: 8200, cost:0.001620\n",
      "step: 8300, cost:0.001592\n",
      "step: 8400, cost:0.001566\n",
      "step: 8500, cost:0.001540\n",
      "step: 8600, cost:0.001515\n",
      "step: 8700, cost:0.001491\n",
      "step: 8800, cost:0.001467\n",
      "step: 8900, cost:0.001445\n",
      "step: 9000, cost:0.001423\n",
      "step: 9100, cost:0.001401\n",
      "step: 9200, cost:0.001381\n",
      "step: 9300, cost:0.001361\n",
      "step: 9400, cost:0.001341\n",
      "step: 9500, cost:0.001322\n",
      "step: 9600, cost:0.001304\n",
      "step: 9700, cost:0.001286\n",
      "step: 9800, cost:0.001268\n",
      "step: 9900, cost:0.001251\n",
      "step:10000, cost:0.001235\n"
     ]
    }
   ],
   "source": [
    "linear1 = torch.nn.Linear(2, 2, bias=True)\n",
    "linear2 = torch.nn.Linear(2, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(\"step:{:5d}, cost:{:5f}\".format(step, cost.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0011],\n",
      "        [0.9989],\n",
      "        [0.9989],\n",
      "        [0.0017]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xor-nn-wide-deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0],  [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:    0, cost:0.697808\n",
      "step:  100, cost:0.693111\n",
      "step:  200, cost:0.693102\n",
      "step:  300, cost:0.693092\n",
      "step:  400, cost:0.693081\n",
      "step:  500, cost:0.693068\n",
      "step:  600, cost:0.693052\n",
      "step:  700, cost:0.693033\n",
      "step:  800, cost:0.693010\n",
      "step:  900, cost:0.692981\n",
      "step: 1000, cost:0.692944\n",
      "step: 1100, cost:0.692896\n",
      "step: 1200, cost:0.692831\n",
      "step: 1300, cost:0.692742\n",
      "step: 1400, cost:0.692612\n",
      "step: 1500, cost:0.692416\n",
      "step: 1600, cost:0.692098\n",
      "step: 1700, cost:0.691539\n",
      "step: 1800, cost:0.690434\n",
      "step: 1900, cost:0.687838\n",
      "step: 2000, cost:0.679710\n",
      "step: 2100, cost:0.640832\n",
      "step: 2200, cost:0.548876\n",
      "step: 2300, cost:0.508318\n",
      "step: 2400, cost:0.487521\n",
      "step: 2500, cost:0.590370\n",
      "step: 2600, cost:0.020090\n",
      "step: 2700, cost:0.007716\n",
      "step: 2800, cost:0.004512\n",
      "step: 2900, cost:0.003111\n",
      "step: 3000, cost:0.002342\n",
      "step: 3100, cost:0.001863\n",
      "step: 3200, cost:0.001538\n",
      "step: 3300, cost:0.001304\n",
      "step: 3400, cost:0.001129\n",
      "step: 3500, cost:0.000993\n",
      "step: 3600, cost:0.000885\n",
      "step: 3700, cost:0.000796\n",
      "step: 3800, cost:0.000723\n",
      "step: 3900, cost:0.000662\n",
      "step: 4000, cost:0.000610\n",
      "step: 4100, cost:0.000564\n",
      "step: 4200, cost:0.000525\n",
      "step: 4300, cost:0.000491\n",
      "step: 4400, cost:0.000460\n",
      "step: 4500, cost:0.000433\n",
      "step: 4600, cost:0.000409\n",
      "step: 4700, cost:0.000387\n",
      "step: 4800, cost:0.000368\n",
      "step: 4900, cost:0.000350\n",
      "step: 5000, cost:0.000334\n",
      "step: 5100, cost:0.000319\n",
      "step: 5200, cost:0.000305\n",
      "step: 5300, cost:0.000292\n",
      "step: 5400, cost:0.000281\n",
      "step: 5500, cost:0.000270\n",
      "step: 5600, cost:0.000260\n",
      "step: 5700, cost:0.000250\n",
      "step: 5800, cost:0.000242\n",
      "step: 5900, cost:0.000233\n",
      "step: 6000, cost:0.000226\n",
      "step: 6100, cost:0.000219\n",
      "step: 6200, cost:0.000212\n",
      "step: 6300, cost:0.000205\n",
      "step: 6400, cost:0.000199\n",
      "step: 6500, cost:0.000194\n",
      "step: 6600, cost:0.000188\n",
      "step: 6700, cost:0.000183\n",
      "step: 6800, cost:0.000178\n",
      "step: 6900, cost:0.000174\n",
      "step: 7000, cost:0.000169\n",
      "step: 7100, cost:0.000165\n",
      "step: 7200, cost:0.000161\n",
      "step: 7300, cost:0.000157\n",
      "step: 7400, cost:0.000154\n",
      "step: 7500, cost:0.000150\n",
      "step: 7600, cost:0.000147\n",
      "step: 7700, cost:0.000143\n",
      "step: 7800, cost:0.000140\n",
      "step: 7900, cost:0.000137\n",
      "step: 8000, cost:0.000135\n",
      "step: 8100, cost:0.000132\n",
      "step: 8200, cost:0.000129\n",
      "step: 8300, cost:0.000127\n",
      "step: 8400, cost:0.000124\n",
      "step: 8500, cost:0.000122\n",
      "step: 8600, cost:0.000120\n",
      "step: 8700, cost:0.000117\n",
      "step: 8800, cost:0.000115\n",
      "step: 8900, cost:0.000113\n",
      "step: 9000, cost:0.000111\n",
      "step: 9100, cost:0.000109\n",
      "step: 9200, cost:0.000108\n",
      "step: 9300, cost:0.000106\n",
      "step: 9400, cost:0.000104\n",
      "step: 9500, cost:0.000102\n",
      "step: 9600, cost:0.000101\n",
      "step: 9700, cost:0.000099\n",
      "step: 9800, cost:0.000098\n",
      "step: 9900, cost:0.000096\n",
      "step:10000, cost:0.000095\n"
     ]
    }
   ],
   "source": [
    "linear1 = torch.nn.Linear(2, 10, bias=True)\n",
    "linear2 = torch.nn.Linear(10, 10, bias=True)\n",
    "linear3 = torch.nn.Linear(10, 10, bias=True)\n",
    "linear4 = torch.nn.Linear(10, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid).to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(\"step:{:5d}, cost:{:5f}\".format(step, cost.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.4741e-05],\n",
      "        [9.9988e-01],\n",
      "        [9.9990e-01],\n",
      "        [8.8276e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model(X))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f67e6345ed4365623c282e2628f58a8ac3d97e420735cebfc003674bed6fdf62"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
