{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\n",
    "    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
    "    'vgg19_bn', 'vgg19',\n",
    "]\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass VGG(nn.Module):\\n    def __init__(self, features, num_classes=1000, init_weights=True):\\n        super(VGG, self).__init__()\\n        \\n        self.features = features #convolution\\n        \\n        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\\n        \\n        self.classifier = nn.Sequential(\\n            nn.Linear(512 * 7 * 7, 4096),\\n            nn.ReLU(True),\\n            nn.Dropout(),\\n            nn.Linear(4096, 4096),\\n            nn.ReLU(True),\\n            nn.Dropout(),\\n            nn.Linear(4096, num_classes),\\n        )#FC layer\\n        \\n        if init_weights:\\n            self._initialize_weights()\\n\\n    def forward(self, x):\\n        x = self.features(x) #Convolution \\n        x = self.avgpool(x) # avgpool\\n        x = x.view(x.size(0), -1) #\\n        x = self.classifier(x) #FC layer\\n        return x\\n\\n    def _initialize_weights(self):\\n        for m in self.modules():\\n            if isinstance(m, nn.Conv2d):\\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\\n                if m.bias is not None:\\n                    nn.init.constant_(m.bias, 0)\\n            elif isinstance(m, nn.BatchNorm2d):\\n                nn.init.constant_(m.weight, 1)\\n                nn.init.constant_(m.bias, 0)\\n            elif isinstance(m, nn.Linear):\\n                nn.init.normal_(m.weight, 0, 0.01)\\n                nn.init.constant_(m.bias, 0)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        \n",
    "        self.features = features #convolution\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )#FC layer\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x) #Convolution \n",
    "        x = self.avgpool(x) # avgpool\n",
    "        x = x.view(x.size(0), -1) #\n",
    "        x = self.classifier(x) #FC layer\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "    \n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    \n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "                     \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], #8 + 3 =11 == vgg11\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], # 10 + 3 = vgg 13\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'], #13 + 3 = vgg 16\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'], # 16 +3 =vgg 19\n",
    "    'custom' : [64,64,64,'M',128,128,128,'M',256,256,256,'M']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv = make_layers(cfg['custom'], batch_norm=True)\n",
    "#CNN = VGG(make_layers(cfg['custom']), num_classes=10, init_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis = visdom.Visdom()\n",
    "vis.close(env='main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tracker(loss_plot, loss_value, num):\n",
    "    vis.line(X=num, Y=loss_value, win = loss_plot, update='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './cifar10', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True, num_workers=4)\n",
    "testset = torchvision.datasets.CIFAR10(root = './cifar10', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataiter = iter(train_loader)\n",
    "#images, labels = dataiter.next()\n",
    "#vis.images(images/2 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models.vgg as vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = [32, 32, 'M', 64, 64, 128, 128, 128, 'M', 256, 256, 256, 512, 512, 512, 'M'] # 13 + 3 = vgg16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        \n",
    "        self.features = features #convolution\n",
    "        \n",
    "        #self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 4, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )#FC layer\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x) #Convolution \n",
    "        #x = self.avgpool(x) # avgpool\n",
    "        x = x.view(x.size(0), -1) #\n",
    "        x = self.classifier(x) #FC layer\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = VGG(vgg.make_layers(cfg), 10, True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a=torch.Tensor(1, 3, 32, 32).to(device)\n",
    "out = vgg16(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(vgg16.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "lr_sche = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(), opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "[1,    30] loss: 2.297\n",
      "[1,    60] loss: 2.275\n",
      "[1,    90] loss: 2.190\n",
      "[2,    30] loss: 2.085\n",
      "[2,    60] loss: 1.983\n",
      "[2,    90] loss: 1.887\n",
      "[3,    30] loss: 1.785\n",
      "[3,    60] loss: 1.719\n",
      "[3,    90] loss: 1.655\n",
      "[4,    30] loss: 1.671\n",
      "[4,    60] loss: 1.568\n",
      "[4,    90] loss: 1.509\n",
      "[5,    30] loss: 1.505\n",
      "[5,    60] loss: 1.456\n",
      "[5,    90] loss: 1.408\n",
      "[6,    30] loss: 1.360\n",
      "[6,    60] loss: 1.344\n",
      "[6,    90] loss: 1.316\n",
      "[7,    30] loss: 1.275\n",
      "[7,    60] loss: 1.252\n",
      "[7,    90] loss: 1.196\n",
      "[8,    30] loss: 1.163\n",
      "[8,    60] loss: 1.146\n",
      "[8,    90] loss: 1.148\n",
      "[9,    30] loss: 1.079\n",
      "[9,    60] loss: 1.075\n",
      "[9,    90] loss: 1.074\n",
      "[10,    30] loss: 1.019\n",
      "[10,    60] loss: 1.029\n",
      "[10,    90] loss: 1.010\n",
      "[11,    30] loss: 0.958\n",
      "[11,    60] loss: 0.962\n",
      "[11,    90] loss: 0.966\n",
      "[12,    30] loss: 0.938\n",
      "[12,    60] loss: 0.915\n",
      "[12,    90] loss: 0.904\n",
      "[13,    30] loss: 0.860\n",
      "[13,    60] loss: 0.879\n",
      "[13,    90] loss: 0.867\n",
      "[14,    30] loss: 0.805\n",
      "[14,    60] loss: 0.811\n",
      "[14,    90] loss: 0.817\n",
      "[15,    30] loss: 0.772\n",
      "[15,    60] loss: 0.767\n",
      "[15,    90] loss: 0.754\n",
      "[16,    30] loss: 0.747\n",
      "[16,    60] loss: 0.719\n",
      "[16,    90] loss: 0.731\n",
      "[17,    30] loss: 0.676\n",
      "[17,    60] loss: 0.694\n",
      "[17,    90] loss: 0.701\n",
      "[18,    30] loss: 0.638\n",
      "[18,    60] loss: 0.649\n",
      "[18,    90] loss: 0.648\n",
      "[19,    30] loss: 0.582\n",
      "[19,    60] loss: 0.599\n",
      "[19,    90] loss: 0.593\n",
      "[20,    30] loss: 0.571\n",
      "[20,    60] loss: 0.571\n",
      "[20,    90] loss: 0.576\n",
      "[21,    30] loss: 0.514\n",
      "[21,    60] loss: 0.497\n",
      "[21,    90] loss: 0.529\n",
      "[22,    30] loss: 0.491\n",
      "[22,    60] loss: 0.485\n",
      "[22,    90] loss: 0.490\n",
      "[23,    30] loss: 0.471\n",
      "[23,    60] loss: 0.453\n",
      "[23,    90] loss: 0.472\n",
      "[24,    30] loss: 0.400\n",
      "[24,    60] loss: 0.411\n",
      "[24,    90] loss: 0.416\n",
      "[25,    30] loss: 0.345\n",
      "[25,    60] loss: 0.368\n",
      "[25,    90] loss: 0.366\n",
      "[26,    30] loss: 0.327\n",
      "[26,    60] loss: 0.325\n",
      "[26,    90] loss: 0.350\n",
      "[27,    30] loss: 0.295\n",
      "[27,    60] loss: 0.300\n",
      "[27,    90] loss: 0.321\n",
      "[28,    30] loss: 0.263\n",
      "[28,    60] loss: 0.264\n",
      "[28,    90] loss: 0.269\n",
      "[29,    30] loss: 0.209\n",
      "[29,    60] loss: 0.236\n",
      "[29,    90] loss: 0.238\n",
      "[30,    30] loss: 0.189\n",
      "[30,    60] loss: 0.175\n",
      "[30,    90] loss: 0.209\n",
      "[31,    30] loss: 0.167\n",
      "[31,    60] loss: 0.164\n",
      "[31,    90] loss: 0.183\n",
      "[32,    30] loss: 0.152\n",
      "[32,    60] loss: 0.157\n",
      "[32,    90] loss: 0.166\n",
      "[33,    30] loss: 0.133\n",
      "[33,    60] loss: 0.124\n",
      "[33,    90] loss: 0.149\n",
      "[34,    30] loss: 0.119\n",
      "[34,    60] loss: 0.134\n",
      "[34,    90] loss: 0.125\n",
      "[35,    30] loss: 0.102\n",
      "[35,    60] loss: 0.100\n",
      "[35,    90] loss: 0.105\n",
      "[36,    30] loss: 0.073\n",
      "[36,    60] loss: 0.096\n",
      "[36,    90] loss: 0.123\n",
      "[37,    30] loss: 0.080\n",
      "[37,    60] loss: 0.075\n",
      "[37,    90] loss: 0.092\n",
      "[38,    30] loss: 0.073\n",
      "[38,    60] loss: 0.084\n",
      "[38,    90] loss: 0.090\n",
      "[39,    30] loss: 0.062\n",
      "[39,    60] loss: 0.058\n",
      "[39,    90] loss: 0.069\n",
      "[40,    30] loss: 0.057\n",
      "[40,    60] loss: 0.060\n",
      "[40,    90] loss: 0.054\n",
      "[41,    30] loss: 0.050\n",
      "[41,    60] loss: 0.049\n",
      "[41,    90] loss: 0.052\n",
      "[42,    30] loss: 0.041\n",
      "[42,    60] loss: 0.041\n",
      "[42,    90] loss: 0.047\n",
      "[43,    30] loss: 0.042\n",
      "[43,    60] loss: 0.043\n",
      "[43,    90] loss: 0.045\n",
      "[44,    30] loss: 0.031\n",
      "[44,    60] loss: 0.033\n",
      "[44,    90] loss: 0.034\n",
      "[45,    30] loss: 0.027\n",
      "[45,    60] loss: 0.033\n",
      "[45,    90] loss: 0.035\n",
      "[46,    30] loss: 0.030\n",
      "[46,    60] loss: 0.032\n",
      "[46,    90] loss: 0.047\n",
      "[47,    30] loss: 0.034\n",
      "[47,    60] loss: 0.026\n",
      "[47,    90] loss: 0.028\n",
      "[48,    30] loss: 0.028\n",
      "[48,    60] loss: 0.023\n",
      "[48,    90] loss: 0.029\n",
      "[49,    30] loss: 0.021\n",
      "[49,    60] loss: 0.026\n",
      "[49,    90] loss: 0.019\n",
      "[50,    30] loss: 0.019\n",
      "[50,    60] loss: 0.017\n",
      "[50,    90] loss: 0.018\n",
      "Finished learning\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    lr_sche.step()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = vgg16(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 29:\n",
    "            loss_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch*len(train_loader) ]))\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 30))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 75 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = vgg16(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f67e6345ed4365623c282e2628f58a8ac3d97e420735cebfc003674bed6fdf62"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
